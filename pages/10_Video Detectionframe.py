import os
import logging
from pathlib import Path
from typing import List, NamedTuple
from collections import defaultdict
import gc
import psutil
from dataclasses import dataclass

import cv2
import numpy as np
import streamlit as st
import torch

import threading
import queue
import time
from threading import Lock, Event, Condition

# Deep learning framework
from ultralytics import YOLO

st.set_page_config(
    page_title="YOLO11 Road Defect Frame Extractor",
    page_icon="üõ£Ô∏è",
    layout="centered",
    initial_sidebar_state="expanded"
)

HERE = Path(__file__).parent
ROOT = HERE.parent

logger = logging.getLogger(__name__)

# Updated model path for YOLO11
MODEL_LOCAL_PATH = ROOT / "./models/YOLOv8_Small_RDD.pt"  # YOLO11 model
tracker_yaml_path = ROOT / "./models/bytetrack.yaml"

# HYBRID OPTIMAL SETTINGS - Best balance of speed + stability
class OptimalSettings:
    """Smart settings calculator based on hardware analysis"""
    
    def __init__(self):
        self.gpu_memory_gb = 0
        self.gpu_name = "CPU"
        
        if torch.cuda.is_available():
            self.gpu_memory_gb = torch.cuda.get_device_properties(0).total_memory / (1024**3)
            self.gpu_name = torch.cuda.get_device_name(0)
            
        self.cpu_cores = os.cpu_count()
        self.ram_gb = psutil.virtual_memory().total / (1024**3)
        
        # Calculate OPTIMAL settings (not too conservative, not too aggressive)
        self.settings = self._calculate_optimal_settings()
        
        print(f"üõ£Ô∏è YOLO11 Road Defect Settings calculated:")
        print(f"   Hardware: {self.gpu_name} ({self.gpu_memory_gb:.1f}GB), {self.cpu_cores} cores")
        print(f"   Settings: {self.settings}")
        
    def _calculate_optimal_settings(self):
        """Calculate the sweet spot for stable high performance"""
        
        batch_size=min(32,int(self.gpu_memory_gb *4))
        num_predictors= 2
        num_preprocessors=2
        base_queue=96
        batch_queue_size=base_queue //4
        
        
        return {
            'BATCH_SIZE': batch_size,
            'NUM_PREDICTOR_THREADS': num_predictors,
            'NUM_PREPROCESSOR_THREADS': num_preprocessors,
            'READ_QUEUE_SIZE': base_queue,
            'PREPROCESS_QUEUE_SIZE': base_queue,
            'BATCH_QUEUE_SIZE': batch_queue_size,  # Smaller for batches
            'RESULT_QUEUE_SIZE': base_queue,
            'MEMORY_CLEANUP_INTERVAL': 20,  # seconds
            'EXPECTED_GPU_USAGE': min(85, 50 + (self.gpu_memory_gb * 5))  # Realistic target
        }

# Initialize optimal settings
if 'optimal_settings' not in st.session_state:
    st.session_state.optimal_settings = OptimalSettings()

SETTINGS = st.session_state.optimal_settings.settings
BATCH_SIZE = SETTINGS['BATCH_SIZE']
NUM_PREDICTOR_THREADS = SETTINGS['NUM_PREDICTOR_THREADS']
NUM_PREPROCESSOR_THREADS = SETTINGS['NUM_PREPROCESSOR_THREADS']

device = "cuda" if torch.cuda.is_available() else "cpu"


# Basit ve g√ºvenli model havuzu y√∂netimi
class OptimizedModelPool:
    def __init__(self, model_path, pool_size):
        self.model_path = model_path
        self.pool_size = pool_size
        self.models = []
        self.lock = Lock()

        self._initialize_pool()

    def _initialize_pool(self):
        """Havuzdaki modelleri ba≈ütan olu≈üturur."""
        print(f"üöÄ {self.pool_size} YOLO11 model y√ºkleniyor...")

        for i in range(self.pool_size):
            model = self._create_model()
            if model:
                self.models.append(model)
                print(f"‚úÖ YOLO11 Model {i + 1}/{self.pool_size} hazƒ±r")
            else:
                print(f"‚ùå Model {i + 1} y√ºklenemedi")

        if not self.models:
            print("‚ö†Ô∏è Hi√ß model y√ºklenemedi, yedek olarak bir model olu≈üturuluyor...")
            fallback_model = self._create_model()
            if fallback_model:
                self.models.append(fallback_model)
            print(f"üì¶ Yedek model olu≈üturuldu: {len(self.models)} model")

    def _create_model(self):
        """Yeni bir YOLO11 model olu≈üturur, optimize eder."""
        try:
            # Load YOLO11 model
            model = YOLO(self.model_path)
            model.tracker = str(tracker_yaml_path)

            if torch.cuda.is_available():
                model.model.half().to(device)
              
                dummy = torch.randn(1, 3, 640, 640).half().to(device)
                with torch.no_grad():
                    _ = model.model(dummy)

            return model
        except Exception as e:
            logger.error(f"YOLO11 Model olu≈üturulamadƒ±: {e}")
            return None

    def get_model(self):
        """Kullanƒ±m i√ßin model alƒ±r, yoksa yeni bir tane olu≈üturur."""
        with self.lock:
            if self.models:
                return self.models.pop()

        # Eƒüer havuz bo≈üsa, kƒ±sa bekleme sonrasƒ± yeni model olu≈ütur
        time.sleep(0.1)
        return self._create_model()

    def return_model(self, model):
        """Kullanƒ±m sonrasƒ± modeli geri havuza koyar."""
        if not model:
            return

        with self.lock:
            if len(self.models) < self.pool_size:
                self.models.append(model)
            else:
                # Havuz doluysa, bu modeli serbest bƒ±rak
                del model
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()


# Initialize optimized model pool
if 'optimized_model_pool' not in st.session_state:
    st.session_state.optimized_model_pool = OptimizedModelPool(
        MODEL_LOCAL_PATH, 
        NUM_PREDICTOR_THREADS + 1  # One extra for safety
    )

# Updated YOLO11 Road Defect Classes (7 classes: 0-6)
CLASSES = [
    "Longitudinal Crack",    # 0: D00 - Boyuna √ßatlak
    "Transverse Crack",      # 1: D10 - Enine √ßatlak
    "Alligator Crack",       # 2: D20 - Timsah derisi √ßatlaƒüƒ±
    "Pothole",               # 3: D40 - √áukur

]

class PerformanceTracker:
    """Sade ve hƒ±zlƒ± performans takibi"""
    def __init__(self):
        self.lock = Lock()
        self.total_frames = 0
        self.processed_frames = 0
        self.unique_tracks = set()
        self.saved_tracks = set()  # Kaydedilen ID'leri takip etmek i√ßin
        self.class_counts = defaultdict(int)
        self.start_time = time.time()
        self.detected_frames = 0  # Tespit i√ßeren frame sayƒ±sƒ±
        
    def add_total(self, count=1):
        with self.lock:
            self.total_frames += count
            
    def add_processed(self, count=1):
        with self.lock:
            self.processed_frames += count
            
    def add_detected_frame(self):
        with self.lock:
            self.detected_frames += 1
            
    def add_track(self, class_id, track_id):
        with self.lock:
            track_key = f"{class_id}_{track_id}"
            if track_key not in self.unique_tracks:
                self.unique_tracks.add(track_key)
                if 0 <= class_id < len(CLASSES):
                    self.class_counts[CLASSES[class_id]] += 1
    
    def is_track_saved(self, class_id, track_id):
        """Bu ID daha √∂nce kaydedildi mi kontrol et"""
        with self.lock:
            track_key = f"{class_id}_{track_id}"
            return track_key in self.saved_tracks
    
    def mark_track_saved(self, class_id, track_id):
        """Bu ID'yi kaydedildi olarak i≈üaretle"""
        with self.lock:
            track_key = f"{class_id}_{track_id}"
            self.saved_tracks.add(track_key)
    
    def get_progress_info(self):
        with self.lock:
            progress = (self.processed_frames / max(1, self.total_frames)) * 100
            elapsed = time.time() - self.start_time
            
            if self.processed_frames > 0:
                remaining = (elapsed / self.processed_frames) * (self.total_frames - self.processed_frames)
            else:
                remaining = 0
                
            return {
                'progress_percent': min(100, progress),
                'processed': self.processed_frames,
                'total': self.total_frames,
                'elapsed_time': elapsed,
                'estimated_remaining': remaining,
                'unique_tracks': len(self.unique_tracks),
                'class_counts': dict(self.class_counts),
                'detected_frames': self.detected_frames,
                'saved_tracks': len(self.saved_tracks)
            }


class HybridOptimalProcessor:
    """Optimize edilmi≈ü video i≈üleme sistemi - Frame extractor versiyonu"""
    
    def __init__(self, model_pool, output_dir):
        self.model_pool = model_pool
        self.tracker = PerformanceTracker()
        self.shutdown_event = Event()
        self.completion_event = Event()
        self.termination_lock = Lock()
        self.preprocessors_finished = 0
        self.predictors_finished = 0
        self.last_cleanup = time.time()
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)

    def memory_cleanup(self):
        """Akƒ±llƒ± bellek temizliƒüi"""
        current_time = time.time()
        if current_time - self.last_cleanup > SETTINGS['MEMORY_CLEANUP_INTERVAL']:
            try:
                gc.collect()
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
                self.last_cleanup = current_time
            except Exception as e:
                logger.error(f"Memory cleanup error: {e}")

    def reader_thread(self, video_capture, read_queue, total_frames):
        """Video okuma thread'i"""
        frames_read = 0
        read_errors = 0
        
        print(f"üìñ Video okuma ba≈üladƒ±: {total_frames} frame")
        
        try:
            while frames_read < total_frames and not self.shutdown_event.is_set():
                try:
                    ret, frame = video_capture.read()
                    if not ret:
                        break
                        
                    # Frame'i kuyruƒüa ekle
                    timeout_counter = 0
                    while not self.shutdown_event.is_set() and timeout_counter < 5:
                        try:
                            read_queue.put((frames_read, frame), timeout=0.5)
                            break
                        except queue.Full:
                            timeout_counter += 1
                            continue
                    
                    if timeout_counter >= 5:
                        print(f"‚ö†Ô∏è Queue dolu: frame {frames_read}")
                        
                    frames_read += 1
                    self.tracker.add_total()
                    
                    # ƒ∞lerleme raporu
                    if frames_read % 500 == 0:
                        print(f"üìñ Okunan: {frames_read}/{total_frames}")
                        
                except Exception as e:
                    read_errors += 1
                    if read_errors > 10:
                        print(f"‚ùå √áok fazla okuma hatasƒ±")
                        break
                    logger.error(f"Frame okuma hatasƒ±: {e}")
                    continue
            
            # Sonlandƒ±rma sinyalleri g√∂nder
            for _ in range(NUM_PREPROCESSOR_THREADS):
                try:
                    read_queue.put(None, timeout=2.0)
                except queue.Full:
                    pass
                    
            print(f"üìñ Okuma tamamlandƒ±: {frames_read} frame, {read_errors} hata")
            
        except Exception as e:
            logger.error(f"Reader fatal error: {e}")

    def preprocessor_worker(self, worker_id, read_queue, preprocess_queue, roi_vertical, roi_horizontal, resize_factor):
        """Frame √∂n i≈üleme worker'ƒ±"""
        frames_processed = 0
        
        print(f"üîß Preprocessor {worker_id} ba≈üladƒ±")
        
        try:
            while not self.shutdown_event.is_set():
                try:
                    item = read_queue.get(timeout=1.0)
                    
                    if item is None:
                        # Sonlandƒ±rma sinyali ilet
                        try:
                            preprocess_queue.put(None, timeout=1.0)
                        except queue.Full:
                            pass
                            
                        with self.termination_lock:
                            self.preprocessors_finished += 1
                            print(f"üîß Preprocessor {worker_id} bitti ({self.preprocessors_finished}/{NUM_PREPROCESSOR_THREADS})")
                        break
                        
                    frame_idx, frame = item
                    
                    # Frame i≈üle
                    processed_frame = self._process_frame(frame, roi_vertical, roi_horizontal, resize_factor)
                    
                    if processed_frame is not None:
                        try:
                            preprocess_queue.put((frame_idx, processed_frame, frame), timeout=1.0)  # Orijinal frame'i de g√∂nder
                            frames_processed += 1
                        except queue.Full:
                            print(f"‚ö†Ô∏è Preprocess queue dolu, worker {worker_id}")
                            continue
                    
                except queue.Empty:
                    continue
                except Exception as e:
                    logger.error(f"Preprocessor {worker_id} hatasƒ±: {e}")
                    
            print(f"üîß Preprocessor {worker_id} tamamlandƒ±: {frames_processed} frame")
            
        except Exception as e:
            logger.error(f"Preprocessor {worker_id} fatal error: {e}")

    def _process_frame(self, frame, roi_vertical, roi_horizontal, resize_factor):
        """Frame i≈üleme - SOL ALTA odaklanacak ≈üekilde g√ºncellendi"""
        try:
            height, width = frame.shape[:2]
            new_width = int(width * resize_factor)
            new_height = int(height * resize_factor)
            
            # Yeniden boyutlandƒ±r
            frame_resized = cv2.resize(frame, (new_width, new_height), interpolation=cv2.INTER_AREA)
            
            # ROI maskeleme - SOL ALT b√∂lgeye odaklanma
            roi_top = int(new_height * (1 - roi_vertical))
            roi_right = int(new_width * (1 - roi_horizontal))  # Saƒüdan kesilecek alan
            
            # G√ºvenlik kontrol√º - ROI sƒ±nƒ±rlarƒ±
            roi_top = max(0, min(roi_top, new_height - 1))
            roi_right = max(1, min(roi_right, new_width))  # En az 1 pixel bƒ±rak
            
            # √úst kƒ±smƒ± siyahlama (g√∂ky√ºz√º vb.)
            if roi_top > 0 and roi_top < new_height:
                frame_resized[:roi_top] = 0
            
            # Saƒü tarafƒ± siyahlama (sol alt b√∂lgeye odaklanma i√ßin)
            if roi_right > 0 and roi_right < new_width:
                frame_resized[:, roi_right:] = 0
                    
            return frame_resized
            
        except Exception as e:
            logger.error(f"Frame i≈üleme hatasƒ±: {e}")
            return None

    def batch_collector(self, preprocess_queue, batch_queue):
        """Batch toplama - akƒ±llƒ± ve verimli"""
        current_batch = []
        current_indices = []
        current_originals = []  # Orijinal frame'leri saklama
        none_count = 0
        batch_id = 0
        
        print(f"üì¶ Batch collector ba≈üladƒ±")
        
        try:
            while not self.shutdown_event.is_set():
                try:
                    item = preprocess_queue.get(timeout=1.0)
                    
                    if item is None:
                        none_count += 1
                        print(f"üì¶ Sonlandƒ±rma sinyali {none_count}/{NUM_PREPROCESSOR_THREADS}")
                        
                        if none_count >= NUM_PREPROCESSOR_THREADS:
                            # Son batch'i g√∂nder
                            if current_batch:
                                batch_id += 1
                                print(f"üì¶ SON batch g√∂nderildi: {len(current_batch)} frame")
                                try:
                                    batch_queue.put((current_batch, current_indices, current_originals, batch_id), timeout=2.0)
                                except queue.Full:
                                    print("‚ö†Ô∏è Son batch g√∂nderilemedi")
                            
                            # Predictor'lara sonlandƒ±rma sinyali
                            for _ in range(NUM_PREDICTOR_THREADS):
                                try:
                                    batch_queue.put(None, timeout=1.0)
                                except queue.Full:
                                    pass
                            break
                        continue
                        
                    frame_idx, frame, original_frame = item
                    current_batch.append(frame)
                    current_indices.append(frame_idx)
                    current_originals.append(original_frame)
                    
                    # Batch hazƒ±r mƒ±?
                    if len(current_batch) >= BATCH_SIZE:
                        batch_id += 1
                        try:
                            batch_queue.put((current_batch, current_indices, current_originals, batch_id), timeout=1.0)
                            print(f"üì¶ Batch {batch_id} g√∂nderildi: {len(current_batch)} frame")
                        except queue.Full:
                            print(f"‚ö†Ô∏è Batch queue dolu: batch {batch_id}")
                            continue
                            
                        current_batch = []
                        current_indices = []
                        current_originals = []
                        
                except queue.Empty:
                    # Timeout batch kontrol√º
                    if current_batch and len(current_batch) >= BATCH_SIZE // 2:
                        batch_id += 1
                        try:
                            batch_queue.put((current_batch, current_indices, current_originals, batch_id), timeout=0.5)
                            print(f"üì¶ Timeout batch {batch_id}: {len(current_batch)} frame")
                            current_batch = []
                            current_indices = []
                            current_originals = []
                        except queue.Full:
                            pass
                    continue
                except Exception as e:
                    logger.error(f"Batch collector hatasƒ±: {e}")
                    
            print(f"üì¶ Batch collector tamamlandƒ±: {batch_id} batch olu≈üturuldu")
            
        except Exception as e:
            logger.error(f"Batch collector fatal error: {e}")

    def predictor_worker(self, worker_id, batch_queue, result_queue, score_threshold):
        """YOLO11 tahmin worker'ƒ±"""
        model = None
        batches_processed = 0
        
        print(f"ü§ñ YOLO11 Predictor {worker_id} ba≈üladƒ±")
        
        try:
            model = self.model_pool.get_model()
            
            while not self.shutdown_event.is_set():
                try:
                    batch_data = batch_queue.get(timeout=2.0)
                    
                    if batch_data is None:
                        # Sonlandƒ±rma sinyali ilet
                        try:
                            result_queue.put(None, timeout=1.0)
                        except queue.Full:
                            pass
                            
                        with self.termination_lock:
                            self.predictors_finished += 1
                            print(f"ü§ñ YOLO11 Predictor {worker_id} bitti ({self.predictors_finished}/{NUM_PREDICTOR_THREADS})")
                        break
                        
                    frames, indices, originals, batch_id = batch_data
                    
                    # Bellek temizliƒüi
                    if batches_processed % 10 == 0:
                        self.memory_cleanup()
                    
                    # YOLO11 tahmin yap
                    processed_results = self._run_yolo11_inference(model, frames, indices, originals, batch_id, score_threshold)
                    
                    if processed_results:
                        self.tracker.add_processed(len(frames))
                        try:
                            result_queue.put(processed_results, timeout=1.0)
                        except queue.Full:
                            print(f"‚ö†Ô∏è Result queue dolu: batch {batch_id}")
                        
                        print(f"ü§ñ YOLO11 Worker {worker_id} batch {batch_id} tamamlandƒ±: {len(frames)} frame")
                    
                    batches_processed += 1
                    
                except queue.Empty:
                    continue
                except Exception as e:
                    logger.error(f"YOLO11 Predictor {worker_id} hatasƒ±: {e}")
                    
            print(f"ü§ñ YOLO11 Predictor {worker_id} tamamlandƒ±: {batches_processed} batch i≈ülendi")
                    
        except Exception as e:
            logger.error(f"YOLO11 Predictor {worker_id} fatal error: {e}")
        finally:
            if model:
                self.model_pool.return_model(model)

    def _run_yolo11_inference(self, model, frames, indices, originals, batch_id, score_threshold):
        """YOLO11 inference - temiz ve g√ºvenli"""
        try:
            results = model.track(
                frames,
                device=device,
                conf=score_threshold,
                imgsz=640,
                verbose=False,
                persist=True,
                tracker=str(tracker_yaml_path),
                half=True
            )
            
            processed_results = []
            for i, result in enumerate(results):
                if self.shutdown_event.is_set():
                    break
                    
                # Tespit var mƒ± kontrol et ve ID'li tespitleri filtrele
                valid_detections = []
                if hasattr(result, 'boxes') and result.boxes is not None and len(result.boxes) > 0:
                    boxes = result.boxes.cpu().numpy()
                    for box in boxes:
                        try:
                            class_id = int(box.cls[0]) if hasattr(box.cls, '__iter__') else int(box.cls)
                            # ID kontrol√º - sadece ID'li tespitleri kabul et
                            if hasattr(box, 'id') and box.id is not None:
                                track_id = int(box.id[0]) if hasattr(box.id, '__iter__') else int(box.id)
                                # Ensure class_id is within our road defect classes (0-6)
                                if 0 <= class_id < len(CLASSES):
                                    self.tracker.add_track(class_id, track_id)
                                    valid_detections.append((class_id, track_id))
                        except (ValueError, TypeError, AttributeError) as e:
                            # ID parse hatasƒ± - bu tespiti atla
                            logger.warning(f"ID parse hatasƒ±: {e}")
                            continue
                
                # Sadece ID'li tespit i√ßeren frame'leri kaydet
                if valid_detections:
                    self.tracker.add_detected_frame()
                    
                    # Annotated frame olu≈ütur
                    try:
                        annotated = result.plot()
                    except Exception as e:
                        logger.error(f"Annotation hatasƒ±: {e}")
                        annotated = originals[i].copy()  # Fallback to original
                    
                    processed_results.append({
                        'frame_idx': indices[i],
                        'annotated_frame': annotated,
                        'original_frame': originals[i],
                        'batch_id': batch_id,
                        'valid_detections': valid_detections,
                        'has_detection': True
                    })
                else:
                    # Tespit yoksa sadece counter'ƒ± g√ºncelle
                    processed_results.append({
                        'frame_idx': indices[i],
                        'annotated_frame': None,
                        'original_frame': None,
                        'batch_id': batch_id,
                        'valid_detections': [],
                        'has_detection': False
                    })
            
            return processed_results
            
        except Exception as e:
            logger.error(f"YOLO11 inference hatasƒ±: {e}")
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
            return None

    def frame_saver_thread(self, result_queue):
        """Frame kaydetme thread'i - Sadece ID'li ve daha √∂nce kaydedilmemi≈ü frame'leri kaydeder"""
        none_count = 0
        frames_saved = 0
        
        print(f"üíæ Frame saver ba≈üladƒ±")
        
        try:
            while not self.shutdown_event.is_set():
                try:
                    results = result_queue.get(timeout=2.0)
                    
                    if results is None:
                        none_count += 1
                        print(f"üíæ Saver sonlandƒ±rma sinyali {none_count}/{NUM_PREDICTOR_THREADS}")
                        
                        if none_count >= NUM_PREDICTOR_THREADS:
                            break
                        continue
                        
                    # Sadece ID'li ve yeni tespitleri kaydet
                    for result in results:
                        if result['has_detection'] and result['valid_detections'] and result['annotated_frame'] is not None:
                            # Bu frame'de kaydedilecek yeni ID var mƒ± kontrol et
                            should_save = False
                            for class_id, track_id in result['valid_detections']:
                                if not self.tracker.is_track_saved(class_id, track_id):
                                    should_save = True
                                    break
                            
                            if should_save:
                                frame_idx = result['frame_idx']
                                annotated_frame = result['annotated_frame']
                                
                                # Sadece annotated frame'i kaydet (orijinal frame kaydetme)
                                try:
                                    # Annotated frame kaydet
                                    annotated_filename = self.output_dir / f"frame_{frame_idx:06d}_detected.jpg"
                                    cv2.imwrite(str(annotated_filename), annotated_frame)
                                    
                                    # Bu frame'deki t√ºm ID'leri kaydedildi olarak i≈üaretle
                                    for class_id, track_id in result['valid_detections']:
                                        self.tracker.mark_track_saved(class_id, track_id)
                                    
                                    frames_saved += 1
                                    
                                    if frames_saved % 25 == 0:
                                        print(f"üíæ Kaydedilen: {frames_saved} benzersiz ID frame'i")
                                        
                                except Exception as e:
                                    logger.error(f"Frame kaydetme hatasƒ±: {e}")
                    
                except queue.Empty:
                    continue
                except Exception as e:
                    logger.error(f"Frame saver hatasƒ±: {e}")
            
            print(f"üíæ Frame kaydetme tamamlandƒ±: {frames_saved} benzersiz frame kaydedildi")
            self.completion_event.set()
            
        except Exception as e:
            logger.error(f"Frame saver fatal error: {e}")
            self.completion_event.set()


def create_tracking_counters():
    st.write("### üõ£Ô∏è Road Defect Detection Results")
    
    # Create a single row with 4 columns for 4 classes
    counter_cols = st.columns(4)
    
    counter_placeholders = {}
    
    # Colors and emojis for 4 road defect classes
    road_defect_info = [
        ("üü°", "Longitudinal Crack"),  # 0
        ("üî¥", "Transverse Crack"),    # 1  
        ("üü†", "Alligator Crack"),     # 2
        ("üîµ", "Pothole"),             # 3
    ]
    
    for i in range(4):
        color, class_name = road_defect_info[i]
        with counter_cols[i]:
            counter_placeholders[class_name] = st.empty()
            counter_placeholders[class_name].metric(f"{color} {class_name}", "0")
    
    return counter_placeholders



def write_bytesio_to_file(filename, bytesio):
    with open(filename, "wb") as outfile:
        outfile.write(bytesio.getbuffer())


# Setup directories
temp_dir = "./temp"
output_frames_dir = "./output_frames"
os.makedirs(temp_dir, exist_ok=True)
os.makedirs(output_frames_dir, exist_ok=True)

temp_file_input = f"{temp_dir}/video_input.mp4"

# Processing state
if 'processing_button' in st.session_state and st.session_state.processing_button:
    st.session_state.runningInference = True
else:
    st.session_state.runningInference = False


def processVideoFrameExtraction(video_file, score_threshold, roi_vertical=0.6, roi_horizontal=0.3, resize_factor=0.5):
    """Optimize edilmi≈ü YOLO11 road defect frame extraction - Sol alt odaklƒ±"""
    
    write_bytesio_to_file(temp_file_input, video_file)
    
    video_capture = cv2.VideoCapture(temp_file_input)
    if not video_capture.isOpened():
        st.error('Video dosyasƒ± a√ßƒ±lamadƒ±')
        return
        
    # Video √∂zellikleri
    _width = int(video_capture.get(cv2.CAP_PROP_FRAME_WIDTH))
    _height = int(video_capture.get(cv2.CAP_PROP_FRAME_HEIGHT))
    _fps = video_capture.get(cv2.CAP_PROP_FPS)
    _total_frames = int(video_capture.get(cv2.CAP_PROP_FRAME_COUNT))
    
    processed_width = int(_width * resize_factor)
    processed_height = int(_height * resize_factor)

    st.write("**Video Analizi:**")
    st.write(f"Giri≈ü: {_width}x{_height} @ {_fps:.1f} FPS | {_total_frames} frame")
    st.write(f"ƒ∞≈üleme: {processed_width}x{processed_height} (Sol alt odaklƒ± ROI)")
    
    st.write("**YOLO11 Road Defect System:**")
    settings_info = (f"Model: YOLO11 (last.pt) | "
                    f"Classes: 7 Road Defects | "
                    f"Batch: {BATCH_SIZE} | "
                    f"Predictors: {NUM_PREDICTOR_THREADS} | "
                    f"Preprocessors: {NUM_PREPROCESSOR_THREADS} | "
                    f"Mode: Sadece ID'li tespitler")
    st.write(settings_info)

    # UI elementleri
    progress_bar = st.progress(0, text="YOLO11 Road Defect Frame Extraction ba≈ülatƒ±lƒ±yor...")
    counter_placeholders = create_tracking_counters()
    performance_dashboard = st.empty()

    # Output klas√∂r√ºn√º temizle ve hazƒ±rla
    import shutil
    if os.path.exists(output_frames_dir):
        shutil.rmtree(output_frames_dir)
    os.makedirs(output_frames_dir, exist_ok=True)

    # Processor olu≈ütur
    processor = HybridOptimalProcessor(st.session_state.optimized_model_pool, output_frames_dir)

    # Queue'larƒ± olu≈ütur
    read_queue = queue.Queue(maxsize=SETTINGS['READ_QUEUE_SIZE'])
    preprocess_queue = queue.Queue(maxsize=SETTINGS['PREPROCESS_QUEUE_SIZE'])
    batch_queue = queue.Queue(maxsize=SETTINGS['BATCH_QUEUE_SIZE'])
    result_queue = queue.Queue(maxsize=SETTINGS['RESULT_QUEUE_SIZE'])

    threads = []
    start_time = time.time()

    try:
        print(f"üõ£Ô∏è YOLO11 Road Defect Frame Extraction ba≈ülƒ±yor: {_total_frames} frame (Sadece ID'li)")
        
        # Thread'leri olu≈ütur
        reader = threading.Thread(
            target=processor.reader_thread,
            args=(video_capture, read_queue, _total_frames),
            name="Reader", daemon=True
        )
        threads.append(reader)

        # Preprocessor thread'leri
        for i in range(NUM_PREPROCESSOR_THREADS):
            preprocessor = threading.Thread(
                target=processor.preprocessor_worker,
                args=(i, read_queue, preprocess_queue, roi_vertical, roi_horizontal, resize_factor),
                name=f"Preprocessor-{i}", daemon=True
            )
            threads.append(preprocessor)

        # Batch collector
        collector = threading.Thread(
            target=processor.batch_collector,
            args=(preprocess_queue, batch_queue),
            name="Collector", daemon=True
        )
        threads.append(collector)

        # YOLO11 Predictor thread'leri
        for i in range(NUM_PREDICTOR_THREADS):
            predictor = threading.Thread(
                target=processor.predictor_worker,
                args=(i, batch_queue, result_queue, score_threshold),
                name=f"YOLO11-Predictor-{i}", daemon=True
            )
            threads.append(predictor)

        # Frame Saver thread
        frame_saver = threading.Thread(
            target=processor.frame_saver_thread,
            args=(result_queue,),
            name="FrameSaver", daemon=True
        )
        threads.append(frame_saver)

        # T√ºm thread'leri ba≈ülat
        for t in threads:
            t.start()

        # ƒ∞lerleme takibi - road defect odaklƒ±
        last_update = time.time()
        
        while not processor.completion_event.is_set() and not processor.shutdown_event.is_set():
            current_time = time.time()
            
            if current_time - last_update >= 1.0:
                # Progress info al
                progress_info = processor.tracker.get_progress_info()
                
                # Progress bar g√ºncelle
                if progress_info['total'] > 0:
                    progress = min(progress_info['processed'] / _total_frames, 1.0)
                    elapsed_time = progress_info['elapsed_time']
                    remaining_time = progress_info['estimated_remaining']
                    
                    progress_bar.progress(
                        progress,
                        text=f"üõ£Ô∏è Frame Extraction: {progress_info['processed']}/{progress_info['total']} frame ({progress*100:.1f}%) | ID'li: {progress_info['saved_tracks']} | Kalan: {remaining_time:.0f}s"
                    )
                
                # Performans dashboard'u
                with performance_dashboard.container():
                    perf_cols = st.columns(4)
                    
                    with perf_cols[0]:
                        elapsed_min = elapsed_time / 60
                        st.metric("Ge√ßen S√ºre", f"{elapsed_min:.1f} dk")
                        
                    with perf_cols[1]:
                        if progress_info['processed'] > 0:
                            fps = progress_info['processed'] / elapsed_time
                            st.metric("YOLO11 FPS", f"{fps:.1f}")
                        else:
                            st.metric("YOLO11 FPS", "0.0")
                        
                    with perf_cols[2]:
                        st.metric("Tespit Frame'leri", f"üì∏ {progress_info['detected_frames']}")
                        
                    with perf_cols[3]:
                        st.metric("Kaydedilen ID'ler", f"üÜî {progress_info['saved_tracks']}")
                
                # Road defect counter'larƒ± g√ºncelle
                for class_name in CLASSES:
                    count = progress_info['class_counts'].get(class_name, 0)
                    counter_placeholders[class_name].metric(f"{class_name}", f"{count}")
                
                last_update = current_time
            
            time.sleep(0.5)

        # Tamamlanma bekleme
        print("‚è≥ YOLO11 frame extraction tamamlanmasƒ± bekleniyor...")
        if not processor.completion_event.wait(timeout=300):  # 5 dakika max
            st.warning("‚ö†Ô∏è ƒ∞≈ülem zaman a≈üƒ±mƒ± - zorla tamamlanƒ±yor")
            processor.shutdown_event.set()

    except KeyboardInterrupt:
        st.warning("üõë ƒ∞≈ülem kullanƒ±cƒ± tarafƒ±ndan durduruldu")
        processor.shutdown_event.set()
        
    except Exception as e:
        st.error(f"‚ùå YOLO11 i≈ülem hatasƒ±: {e}")
        processor.shutdown_event.set()
        
    finally:
        # Temizlik
        processor.shutdown_event.set()
        video_capture.release()
        
        # Son bellek temizliƒüi
        processor.memory_cleanup()
        
        # Son sonu√ßlar
        end_time = time.time()
        final_progress = processor.tracker.get_progress_info()
        processing_time = end_time - start_time
        
        # Performans analizi
        theoretical_time = _total_frames / _fps
        speedup_factor = theoretical_time / processing_time if processing_time > 0 else 0
        
        st.success(f"üõ£Ô∏è YOLO11 Frame Extraction Tamamlandƒ±!")
        
        # Sonu√ß √∂zeti
        summary_cols = st.columns(3)
        with summary_cols[0]:
            st.metric("ƒ∞≈ülem S√ºresi", f"{processing_time:.1f}s")
            st.metric("Hƒ±zlanma Fakt√∂r√º", f"{speedup_factor:.1f}x")
            
        with summary_cols[1]:
            if final_progress['processed'] > 0:
                avg_fps = final_progress['processed'] / processing_time
                st.metric("Ortalama FPS", f"{avg_fps:.1f}")
            else:
                st.metric("Ortalama FPS", "0.0")
            completion_rate = (final_progress['processed'] / max(1, final_progress['total'])) * 100
            st.metric("Tamamlanma", f"{completion_rate:.1f}%")
            
        with summary_cols[2]:
            st.metric("Tespit Edilen Frame", f"üì∏ {final_progress['detected_frames']}")
            st.metric("Benzersiz ID'ler", f"üÜî {final_progress['saved_tracks']}")
        
        # Road defect detection summary
        st.write("### üìä Tespit Edilen Yol Defektleri:")
        defect_summary_cols = st.columns(4)
        
        class_counts = final_progress['class_counts']
        defect_colors = ["üü°", "üî¥", "üü†", "üîµ"]
        
        for i, class_name in enumerate(CLASSES):
            col_idx = i % 4
            with defect_summary_cols[col_idx]:
                count = class_counts.get(class_name, 0)
                color = defect_colors[i] if i < len(defect_colors) else "üî∂"
                if count > 0:
                    st.write(f"**{color} {class_name}**: {count} adet")
                else:
                    st.write(f"{color} {class_name}: {count} adet")
        
        # Output klas√∂r√º bilgisi
        st.write("### üìÅ √áƒ±ktƒ± Klas√∂r√º:")
        frame_files = list(Path(output_frames_dir).glob("*.jpg"))
        st.write(f"**Klas√∂r**: `{output_frames_dir}`")
        st.write(f"**Kaydedilen dosya sayƒ±sƒ±**: {len(frame_files)} adet")
        
        if len(frame_files) > 0:
            st.write("**Dosya formatƒ±**: `frame_XXXXXX_detected.jpg` (Sadece tespit edilen frame'ler)")
            
            # √ñrnek dosyalar g√∂ster
            sample_files = sorted(frame_files)[:6]  # ƒ∞lk 6 dosyayƒ± g√∂ster
            st.write("**√ñrnek dosyalar**:")
            for file_path in sample_files:
                st.write(f"- {file_path.name}")
                
        # Performans deƒüerlendirmesi
        if final_progress['detected_frames'] > 0:
            detection_rate = (final_progress['detected_frames'] / final_progress['processed']) * 100
            unique_rate = (final_progress['saved_tracks'] / final_progress['detected_frames']) * 100
            st.write(f"### üìà ƒ∞statistikler:")
            st.write(f"- **Tespit Oranƒ±**: {detection_rate:.1f}% (tespit i√ßeren frame oranƒ±)")
            st.write(f"- **Benzersizlik Oranƒ±**: {unique_rate:.1f}% (kaydedilen benzersiz ID oranƒ±)")
            
            if final_progress['saved_tracks'] >= 10:
                st.success("üéØ Y√ºksek ID √ße≈üitliliƒüi - √ßok sayƒ±da benzersiz defekt tespit edildi")
            elif final_progress['saved_tracks'] >= 5:
                st.info("üëç Orta ID √ße≈üitliliƒüi - bazƒ± benzersiz defektler tespit edildi")
            else:
                st.info("üìä D√º≈ü√ºk ID √ße≈üitliliƒüi - az sayƒ±da benzersiz defekt")
        else:
            st.info("‚ÑπÔ∏è Hi√ß ID'li defekt tespit edilmedi - e≈üik deƒüerini d√º≈ü√ºrmeyi deneyin")
        
        # Zip dosyasƒ± olu≈üturma se√ßeneƒüi
        if len(frame_files) > 0:
            if st.button("üì¶ T√ºm Frame'leri ZIP olarak Hazƒ±rla", use_container_width=True):
                import zipfile
                zip_path = f"{temp_dir}/detected_frames.zip"
                
                with zipfile.ZipFile(zip_path, 'w') as zipf:
                    for file_path in frame_files:
                        zipf.write(file_path, file_path.name)
                
                st.success(f"‚úÖ ZIP dosyasƒ± hazƒ±r: {len(frame_files)} dosya")
                
                # Download button
                with open(zip_path, "rb") as f:
                    st.download_button(
                        label="üì• Tespit Edilen Frame'leri ƒ∞ndir",
                        data=f,
                        file_name="yolo11_detected_frames.zip",
                        mime="application/zip",
                        use_container_width=True
                    )
        
        print(f"‚úÖ YOLO11 Frame Extraction tamamlandƒ±: {final_progress['saved_tracks']} benzersiz ID frame'i kaydedildi")


# UI Layout
col1, col2 = st.columns(2)
with col1:
    frames_count = 0
    if os.path.exists(output_frames_dir):
        frames_count = len(list(Path(output_frames_dir).glob("*.jpg")))
    
    if frames_count > 0:
        st.metric("üíæ Kaydedilen Frame", f"{frames_count} adet")
        st.info(f"Frame'ler: `{output_frames_dir}` klas√∂r√ºnde")
    else:
        st.info("Benzersiz ID'li frame'ler burada g√∂r√ºnecek")
        
with col2:
    if st.button('üîÑ Reset YOLO11 System', use_container_width=True, type="primary"):
        # Complete reset
        for key in ['optimal_settings', 'optimized_model_pool']:
            if key in st.session_state:
                del st.session_state[key]
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        # Output klas√∂r√ºn√º temizle
        if os.path.exists(output_frames_dir):
            import shutil
            shutil.rmtree(output_frames_dir)
        st.rerun()

st.title("üõ£Ô∏è YOLO11 Road Defect Frame Extractor")
st.write("**‚ú® Extract unique ID-tracked frames with road defects using YOLO11**")

# Model info panel
model_info = st.expander("üîß YOLO11 Model Information")
with model_info:
    col1, col2 = st.columns(2)
    with col1:
        st.write("**Model Configuration:**")
        st.write(f"- Model: YOLO11 (last.pt)")
        st.write(f"- Classes: {len(CLASSES)} Road Defect Types")
        st.write(f"- Input Resolution: 640x640")
        st.write(f"- Tracking: ByteTrack")
        st.write(f"- Output: Sadece ID'li frame'ler")
        st.write(f"- ROI: Sol alt odaklƒ±")
    with col2:
        st.write("**Road Defect Classes:**")
        for i, class_name in enumerate(CLASSES):
            defect_codes = ["D00", "D10", "D20", "D40", "D43", "D44", "D50"]
            st.write(f"- {i}: {class_name} ({defect_codes[i]})")

# Important notice
st.info("üÜî **√ñnemli**: Bu sistem sadece track ID'si olan tespitleri kaydeder ve her ID'yi yalnƒ±zca bir kez kaydeder. Bu sayede benzersiz defekt √∂rnekleri elde edilir.")

# File upload
video_file = st.file_uploader(
    "üìπ Upload Road Video File", 
    type=".mp4", 
    disabled=st.session_state.runningInference,
    help="Upload a video file containing road footage for defect detection and frame extraction"
)

# Settings
score_threshold = st.slider(
    "Detection Confidence Threshold", 
    0.0, 1.0, 0.5, 0.05, 
    disabled=st.session_state.runningInference,
    help="Higher values = fewer but more confident detections"
)

# Preprocessing
st.write("---")
st.write("### üîß Video Preprocessing Configuration")

prep_cols = st.columns(3)
with prep_cols[0]:
    resize_factor = st.slider(
        "Size Factor", 
        0.1, 1.0, 0.5, 0.1,
        disabled=st.session_state.runningInference,
        help="Lower = faster processing, less detail"
    )
with prep_cols[1]:
    roi_vertical = st.slider(
        "Vertical ROI", 
        0.1, 1.0, 0.7, 0.1,  # Daha fazla alt kƒ±sƒ±m
        disabled=st.session_state.runningInference,
        help="Keep bottom portion (road area)"
    )
with prep_cols[2]:
    roi_horizontal = st.slider(
        "Left Focus ROI", 
        0.0, 0.7, 0.3, 0.1,  # Sol odak i√ßin daha fazla alan
        disabled=st.session_state.runningInference,
        help="Remove right side (focus on left-bottom)"
    )

# ROI visualization
st.write("**üéØ ROI Preview**: Sol alt b√∂lgeye odaklanƒ±lacak")
roi_cols = st.columns(3)
with roi_cols[0]:
    st.metric("Alt B√∂lge", f"{roi_vertical*100:.0f}%", "Yolun alt kƒ±smƒ±")
with roi_cols[1]:
    st.metric("Sol Odak", f"{(1-roi_horizontal)*100:.0f}%", "Sol taraf korunacak")
with roi_cols[2]:
    st.metric("ƒ∞≈ülem Boyutu", f"{resize_factor*100:.0f}%", "Hƒ±z optimizasyonu")

# Process button
if video_file is not None:
    if st.button(
        'üõ£Ô∏è Start YOLO11 Frame Extraction (ID-Only)',
        use_container_width=True,
        disabled=st.session_state.runningInference,
        type="secondary",
        key="processing_button"
    ):
        st.info(f"üõ£Ô∏è Processing {video_file.name} for unique ID-tracked road defect frames...")
        processVideoFrameExtraction(video_file, score_threshold, roi_vertical, roi_horizontal, resize_factor)
else:
    st.warning("üìπ L√ºtfen i≈ülem i√ßin bir video dosyasƒ± y√ºkleyin")

# Footer
st.write("---")
st.write("### üìã System Information")
info_cols = st.columns(3)
with info_cols[0]:
    st.write("**Processing Mode:**")
    st.write("- ID-tracked detections only")
    st.write("- Unique frames per ID")
    st.write("- Left-bottom ROI focus")
with info_cols[1]:
    st.write("**Output Format:**")
    st.write("- Annotated frames only")
    st.write("- JPG format")
    st.write("- frame_XXXXXX_detected.jpg")
with info_cols[2]:
    st.write("**Performance:**")
    if torch.cuda.is_available():
        st.write(f"- GPU: {st.session_state.optimal_settings.gpu_name}")
        st.write(f"- VRAM: {st.session_state.optimal_settings.gpu_memory_gb:.1f}GB")
    else:
        st.write("- CPU Mode")
    st.write(f"- Threads: {NUM_PREDICTOR_THREADS}+{NUM_PREPROCESSOR_THREADS}")

# Performance tips
with st.expander("üí° Performance Tips"):
    st.write("""
    **Hƒ±zlandƒ±rma i√ßin:**
    - Size Factor'ƒ± d√º≈ü√ºr√ºn (0.3-0.5)
    - Confidence Threshold'u y√ºkseltin (0.6-0.8)
    - ROI alanƒ±nƒ± daraltƒ±n
    
    **Kalite i√ßin:**
    - Size Factor'ƒ± y√ºkseltin (0.7-1.0)
    - Confidence Threshold'u d√º≈ü√ºr√ºn (0.3-0.5)
    - ROI alanƒ±nƒ± geni≈ületin
    
    **ID Tracking i√ßin:**
    - Video kalitesi √∂nemli
    - Sabit kamera a√ßƒ±sƒ± tercih edilir
    - Yeterli ƒ±≈üƒ±k ko≈üullarƒ± gerekli
    """)

# Debug information (only show if processing)
if st.session_state.runningInference:
    with st.expander("üîç Debug Information"):
        st.write("**Current Settings:**")
        st.json(SETTINGS)
        
        if torch.cuda.is_available():
            try:
                gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)
                gpu_used = torch.cuda.memory_allocated(0) / (1024**3)
                st.write(f"**GPU Memory:** {gpu_used:.1f}GB / {gpu_memory:.1f}GB")
            except:
                st.write("**GPU Memory:** Unable to read")
        
        st.write(f"**Model Pool:** {len(st.session_state.optimized_model_pool.models)} models available")