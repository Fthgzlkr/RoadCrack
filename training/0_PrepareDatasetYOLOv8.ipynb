{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Immport\n",
    "from xml.dom import minidom\n",
    "import bs4 as bs\n",
    "import os\n",
    "from pathlib import Path\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import os\n",
    "from pathlib import Path\n",
    "import bs4 as bs\n",
    "\n",
    "def convertPascal2YOLOv8(filePath, outputDir):\n",
    "    \"\"\"\n",
    "    Pascal VOC formatındaki XML dosyalarını YOLOv8 formatına çevirir\n",
    "    ID'leri ardışık olacak şekilde yeniden düzenler (0-7)\n",
    "    \"\"\"\n",
    "    # ⚠️ YENİ ARDIIŞIK ID MAPPING (0-7, boşluk yok)\n",
    "    class_mapping = {\n",
    "        \"D00\": 0,     # Longitudinal Crack\n",
    "        \"D10\": 1,     # Transverse Crack\n",
    "        \"D20\": 2,     # Alligator Crack\n",
    "        \"D40\": 3,     # Pothole\n",
    "        \"D43\": 4,     # Crosswalk Blur (ESKİ: 6 → YENİ: 4)\n",
    "        \"D44\": 5,     # White Line (ESKİ: 7 → YENİ: 5)\n",
    "        \"D50\": 6,     # Utility Hole (ESKİ: 8 → YENİ: 6)\n",
    "        \"Repair\": 7   # Repair (ESKİ: 9 → YENİ: 7)\n",
    "    }\n",
    "\n",
    "    # Sadece bunlar yazılacak\n",
    "    included_classes = {\"D00\", \"D10\", \"D20\", \"D40\", \"D43\", \"D44\", \"D50\", \"Repair\"}\n",
    "\n",
    "    written_class_counter = Counter()\n",
    "    ignored_class_counter = Counter()\n",
    "\n",
    "    try:\n",
    "        with open(filePath, \"r\", encoding=\"utf-8\") as file:\n",
    "            contents = file.read()\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Dosya okuma hatası: {filePath} - {e}\")\n",
    "        return written_class_counter, ignored_class_counter\n",
    "\n",
    "    soup = bs.BeautifulSoup(contents, 'lxml-xml')\n",
    "    \n",
    "    # Görüntü boyutlarını al\n",
    "    size_tag = soup.find(\"size\")\n",
    "    if not size_tag:\n",
    "        print(f\"⚠️ Uyarı: {filePath} dosyasında size tag bulunamadı!\")\n",
    "        return written_class_counter, ignored_class_counter\n",
    "        \n",
    "    try:\n",
    "        image_width = int(size_tag.find(\"width\").text)\n",
    "        image_height = int(size_tag.find(\"height\").text)\n",
    "    except (ValueError, AttributeError) as e:\n",
    "        print(f\"⚠️ Görüntü boyut hatası: {filePath} - {e}\")\n",
    "        return written_class_counter, ignored_class_counter\n",
    "\n",
    "    objects = soup.find_all(\"object\")\n",
    "    output_lines = []\n",
    "\n",
    "    for obj in objects:\n",
    "        try:\n",
    "            class_name = obj.find(\"name\").text.strip()\n",
    "        except AttributeError:\n",
    "            continue\n",
    "\n",
    "        # Sınıf dahil edilmeyecekse atla\n",
    "        if class_name not in included_classes:\n",
    "            ignored_class_counter[class_name] += 1\n",
    "            continue\n",
    "\n",
    "        # Mapping'de yoksa atla  \n",
    "        if class_name not in class_mapping:\n",
    "            ignored_class_counter[class_name] += 1\n",
    "            continue\n",
    "\n",
    "        # YENİ ardışık ID'yi al\n",
    "        class_id = class_mapping[class_name]\n",
    "\n",
    "        # Bounding box koordinatlarını al\n",
    "        try:\n",
    "            bbox = obj.find(\"bndbox\")\n",
    "            xmin = float(bbox.find(\"xmin\").text)\n",
    "            ymin = float(bbox.find(\"ymin\").text)\n",
    "            xmax = float(bbox.find(\"xmax\").text)\n",
    "            ymax = float(bbox.find(\"ymax\").text)\n",
    "        except (ValueError, AttributeError) as e:\n",
    "            print(f\"⚠️ Bbox hatası {class_name}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # YOLO formatına çevir\n",
    "        w = xmax - xmin\n",
    "        h = ymax - ymin\n",
    "        cx = xmin + w / 2\n",
    "        cy = ymin + h / 2\n",
    "\n",
    "        # Normalize et\n",
    "        w /= image_width\n",
    "        h /= image_height\n",
    "        cx /= image_width\n",
    "        cy /= image_height\n",
    "\n",
    "        # Geçerli koordinat kontrolü\n",
    "        if w <= 0 or h <= 0 or cx < 0 or cy < 0 or cx > 1 or cy > 1:\n",
    "            print(f\"⚠️ Geçersiz koordinat {class_name}: cx={cx:.3f}, cy={cy:.3f}, w={w:.3f}, h={h:.3f}\")\n",
    "            continue\n",
    "\n",
    "        # YENİ ID ile YOLO formatında yaz\n",
    "        output_lines.append(f\"{class_id} {cx:.6f} {cy:.6f} {w:.6f} {h:.6f}\\n\")\n",
    "        written_class_counter[class_name] += 1\n",
    "\n",
    "    # Çıktı dosyası oluştur (boş olsa bile)\n",
    "    outputFilename = os.path.splitext(os.path.basename(filePath))[0] + \".txt\"\n",
    "    os.makedirs(outputDir, exist_ok=True)\n",
    "    outputPath = Path(outputDir) / outputFilename\n",
    "\n",
    "    with open(outputPath, 'w') as f:\n",
    "        f.writelines(output_lines)\n",
    "\n",
    "    return written_class_counter, ignored_class_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 XML dosyalarını YOLO formatına çevirme işlemi başlatılıyor...\n",
      "======================================================================\n",
      "\n",
      "🔍 xmls klasöründe 10506 XML bulundu.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing xmls:  10%|▉         | 1014/10506 [00:12<01:54, 82.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Geçersiz koordinat D20: cx=0.330, cy=0.791, w=0.000, h=0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing xmls: 100%|██████████| 10506/10506 [02:14<00:00, 78.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 xmls klasöründe 7706 XML bulundu.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing xmls: 100%|██████████| 7706/7706 [01:21<00:00, 94.50it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 xmls klasöründe 2401 XML bulundu.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing xmls: 100%|██████████| 2401/2401 [00:28<00:00, 84.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 xmls klasöründe 1977 XML bulundu.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing xmls: 100%|██████████| 1977/1977 [00:27<00:00, 72.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 xmls klasöründe 2829 XML bulundu.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing xmls: 100%|██████████| 2829/2829 [00:31<00:00, 89.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 xmls klasöründe 8161 XML bulundu.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing xmls: 100%|██████████| 8161/8161 [01:40<00:00, 80.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 xmls klasöründe 4805 XML bulundu.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing xmls: 100%|██████████| 4805/4805 [00:58<00:00, 81.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "📊 TÜM DOSYALAR İÇİN TOPLAM SINIF İSTATİSTİKLERİ\n",
      "======================================================================\n",
      "\n",
      "✅ YAZILAN SINIFLAR TOPLAM SAYISI:\n",
      " - D00: 26,016 adet\n",
      " - D10: 11,830 adet\n",
      " - D20: 10,616 adet\n",
      " - D40: 6,544 adet\n",
      " - D43: 793 adet\n",
      " - D44: 5,057 adet\n",
      " - D50: 3,581 adet\n",
      " - Repair: 1,046 adet\n",
      "\n",
      "📈 Toplam yazılan nesne sayısı: 65,483\n",
      "\n",
      "❌ YAZILMAYAN SINIFLAR TOPLAM SAYISI:\n",
      "Toplam atlanan nesne sayısı: 228\n",
      " - Block crack: 3 adet\n",
      " - D01: 179 adet\n",
      " - D0w0: 1 adet\n",
      " - D11: 45 adet\n",
      "\n",
      "🎉 XML → YOLO dönüşümü tamamlandı!\n",
      "📁 Label dosyaları her ülkenin 'labels' klasöründe oluşturuldu.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "# Ana dizin\n",
    "ROOTDIR = r\"C:\\Users\\fthgz\\OneDrive\\Belgeler\\RoadDamageDetection-main\"\n",
    "\n",
    "# İşlenecek ülkeler\n",
    "CountryListDir = [\n",
    "    \"RDD2022_all_countries/Japan/Japan/train/annotations/xmls\",\n",
    "    \"RDD2022_all_countries/India/India/train/annotations/xmls\",\n",
    "    \"RDD2022_all_countries/China_Drone/China_Drone/train/annotations/xmls\",\n",
    "    \"RDD2022_all_countries/China_MotorBike/China_MotorBike/train/annotations/xmls\",\n",
    "    \"RDD2022_all_countries/Czech/Czech/train/annotations/xmls\",\n",
    "    \"RDD2022_all_countries/Norway/Norway/train/annotations/xmls\",\n",
    "    \"RDD2022_all_countries/United_States/United_States/train/annotations/xmls\",\n",
    "]\n",
    "\n",
    "# Toplam sayaçlar\n",
    "total_written_counter = Counter()\n",
    "total_ignored_counter = Counter()\n",
    "\n",
    "print(\"🚀 XML dosyalarını YOLO formatına çevirme işlemi başlatılıyor...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for country_rel_path in CountryListDir:\n",
    "    country_abs_path = os.path.join(ROOTDIR, country_rel_path)\n",
    "    \n",
    "    # Dizin kontrolü\n",
    "    if not os.path.exists(country_abs_path):\n",
    "        print(f\"⚠️ Dizin bulunamadı: {country_abs_path}\")\n",
    "        continue\n",
    "    \n",
    "    # XML dosyalarını bul\n",
    "    fileList = sorted(glob.glob(os.path.join(country_abs_path, \"*.xml\")))\n",
    "    \n",
    "    if not fileList:\n",
    "        print(f\"⚠️ {country_rel_path} klasöründe XML dosyası bulunamadı.\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n🔍 {os.path.basename(country_rel_path)} klasöründe {len(fileList)} XML bulundu.\")\n",
    "    \n",
    "    # Çıktı dizinini belirle (labels klasörü oluştur)\n",
    "    output_labels_path = Path(country_abs_path).parent.parent / \"labels\"\n",
    "    \n",
    "    # Her XML dosyasını işle\n",
    "    for file in tqdm(fileList, desc=f\"Processing {os.path.basename(country_rel_path)}\"):\n",
    "        written, ignored = convertPascal2YOLOv8(file, output_labels_path)\n",
    "        total_written_counter.update(written)\n",
    "        total_ignored_counter.update(ignored)\n",
    "\n",
    "# İşlem bitince toplu istatistikleri yazdır\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"📊 TÜM DOSYALAR İÇİN TOPLAM SINIF İSTATİSTİKLERİ\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n✅ YAZILAN SINIFLAR TOPLAM SAYISI:\")\n",
    "if total_written_counter:\n",
    "    for cls, count in sorted(total_written_counter.items()):\n",
    "        print(f\" - {cls}: {count:,} adet\")\n",
    "    print(f\"\\n📈 Toplam yazılan nesne sayısı: {sum(total_written_counter.values()):,}\")\n",
    "else:\n",
    "    print(\" Hiç nesne yazılmadı!\")\n",
    "\n",
    "print(\"\\n❌ YAZILMAYAN SINIFLAR TOPLAM SAYISI:\")\n",
    "if total_ignored_counter:\n",
    "    total_ignored = sum(total_ignored_counter.values())\n",
    "    print(f\"Toplam atlanan nesne sayısı: {total_ignored:,}\")\n",
    "    for cls, count in sorted(total_ignored_counter.items()):\n",
    "        print(f\" - {cls}: {count:,} adet\")\n",
    "else:\n",
    "    print(\" Hiç nesne atlanmadı!\")\n",
    "\n",
    "print(f\"\\n🎉 XML → YOLO dönüşümü tamamlandı!\")\n",
    "print(f\"📁 Label dosyaları her ülkenin 'labels' klasöründe oluşturuldu.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "def CopyDatasetSplit(baseDir):\n",
    "    \"\"\"\n",
    "    Veri setini %80 eğitim, %20 doğrulama olarak böler ve kopyalar\n",
    "    Boş etiketli görüntüleri %5 oranında dahil eder\n",
    "    \"\"\"\n",
    "    random.seed(1337)  # Reproducible results\n",
    "    \n",
    "    baseOutputDir = r\"C:\\Users\\fthgz\\OneDrive\\Belgeler\\RoadDamageDetection-main\\RDD2022_SPLIT\"\n",
    "    \n",
    "    baseImageDir = os.path.join(baseDir, \"images\")\n",
    "    baseAnnotDir = os.path.join(baseDir, \"labels\")\n",
    "    \n",
    "    # Dizin kontrolü\n",
    "    if not os.path.exists(baseImageDir):\n",
    "        print(f\"⚠️ Images dizini bulunamadı: {baseImageDir}\")\n",
    "        return\n",
    "        \n",
    "    if not os.path.exists(baseAnnotDir):\n",
    "        print(f\"⚠️ Labels dizini bulunamadı: {baseAnnotDir}\")\n",
    "        return\n",
    "    \n",
    "    # Tüm dosyaları listele\n",
    "    image_list_all = sorted(glob.glob(os.path.join(baseImageDir, \"*\")))\n",
    "    annot_list_all = sorted(glob.glob(os.path.join(baseAnnotDir, \"*\")))\n",
    "    \n",
    "    if not image_list_all:\n",
    "        print(f\"⚠️ Hiç görüntü dosyası bulunamadı: {baseImageDir}\")\n",
    "        return\n",
    "        \n",
    "    if not annot_list_all:\n",
    "        print(f\"⚠️ Hiç etiket dosyası bulunamadı: {baseAnnotDir}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"📊 Bulunan dosyalar - Görüntü: {len(image_list_all)}, Etiket: {len(annot_list_all)}\")\n",
    "    \n",
    "    # 🟡 Boş etiketli görüntüler %5 oranında dahil edilecek\n",
    "    backgroundImages_Percentage = 0.05\n",
    "    image_list = []\n",
    "    annot_list = []\n",
    "    max_background_image = int(len(image_list_all) * backgroundImages_Percentage)\n",
    "    background_counter = 0\n",
    "    files_with_labels = 0\n",
    "    \n",
    "    # Dosya eşleştirmesi ve filtreleme\n",
    "    min_length = min(len(image_list_all), len(annot_list_all))\n",
    "    \n",
    "    for i in range(min_length):\n",
    "        try:\n",
    "            with open(annot_list_all[i], 'r', encoding='utf-8') as f:\n",
    "                annot_content = f.read().strip()\n",
    "                \n",
    "            if annot_content:  # Etiket varsa\n",
    "                image_list.append(image_list_all[i])\n",
    "                annot_list.append(annot_list_all[i])\n",
    "                files_with_labels += 1\n",
    "            elif background_counter < max_background_image:  # Boş etiket ama limitte\n",
    "                image_list.append(image_list_all[i])\n",
    "                annot_list.append(annot_list_all[i])\n",
    "                background_counter += 1\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Dosya okuma hatası: {annot_list_all[i]} - {e}\")\n",
    "            continue\n",
    "    \n",
    "    if not image_list:\n",
    "        print(\"⚠️ İşlenecek dosya bulunamadı!\")\n",
    "        return\n",
    "    \n",
    "    print(f\"📈 Etiketli dosyalar: {files_with_labels}\")\n",
    "    print(f\"📉 Boş etiketli dosyalar (dahil edilen): {background_counter}\")\n",
    "    print(f\"📊 Toplam işlenecek dosya: {len(image_list)}\")\n",
    "    \n",
    "    # 🔀 %80 eğitim, %20 doğrulama\n",
    "    dataset_length = len(image_list)\n",
    "    split_ratio = 0.8\n",
    "    middle_point = round(split_ratio * dataset_length)\n",
    "    \n",
    "    numberList = list(range(dataset_length))\n",
    "    random.shuffle(numberList)\n",
    "    trainNumberList = numberList[:middle_point]\n",
    "    validNumberList = numberList[middle_point:]\n",
    "    \n",
    "    print(f\"📊 Toplam Eğitim/Doğrulama Sayısı: {len(trainNumberList)} / {len(validNumberList)}\")\n",
    "    \n",
    "    # 🟩 Eğitim verileri\n",
    "    print(\"📥 Eğitim verileri kopyalanıyor...\")\n",
    "    train_images_dir = os.path.join(baseOutputDir, \"images\", \"train\")\n",
    "    train_labels_dir = os.path.join(baseOutputDir, \"labels\", \"train\")\n",
    "    os.makedirs(train_images_dir, exist_ok=True)\n",
    "    os.makedirs(train_labels_dir, exist_ok=True)\n",
    "    \n",
    "    for i in tqdm(trainNumberList, desc=\"Train Copy\"):\n",
    "        try:\n",
    "            shutil.copy2(image_list[i], train_images_dir)\n",
    "            shutil.copy2(annot_list[i], train_labels_dir)\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Eğitim kopyalama hatası: {e}\")\n",
    "    \n",
    "    # 🟦 Doğrulama verileri\n",
    "    print(\"📥 Doğrulama verileri kopyalanıyor...\")\n",
    "    val_images_dir = os.path.join(baseOutputDir, \"images\", \"val\")\n",
    "    val_labels_dir = os.path.join(baseOutputDir, \"labels\", \"val\")\n",
    "    os.makedirs(val_images_dir, exist_ok=True)\n",
    "    os.makedirs(val_labels_dir, exist_ok=True)\n",
    "    \n",
    "    for i in tqdm(validNumberList, desc=\"Val Copy\"):\n",
    "        try:\n",
    "            shutil.copy2(image_list[i], val_images_dir)\n",
    "            shutil.copy2(annot_list[i], val_labels_dir)\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Doğrulama kopyalama hatası: {e}\")\n",
    "    \n",
    "    print(f\"✅ {os.path.basename(baseDir)} için dataset split tamamlandı!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌍 Tüm ülkeler için dataset split işlemi başlatılıyor...\n",
      "============================================================\n",
      "\n",
      "🚀 İşleniyor: Japan\n",
      "----------------------------------------\n",
      "📊 Bulunan dosyalar - Görüntü: 10506, Etiket: 10506\n",
      "📈 Etiketli dosyalar: 9712\n",
      "📉 Boş etiketli dosyalar (dahil edilen): 525\n",
      "📊 Toplam işlenecek dosya: 10237\n",
      "📊 Toplam Eğitim/Doğrulama Sayısı: 8190 / 2047\n",
      "📥 Eğitim verileri kopyalanıyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Copy: 100%|██████████| 8190/8190 [01:44<00:00, 78.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Doğrulama verileri kopyalanıyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val Copy: 100%|██████████| 2047/2047 [00:26<00:00, 76.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ train için dataset split tamamlandı!\n",
      "✅ Japan başarıyla tamamlandı!\n",
      "\n",
      "🚀 İşleniyor: India\n",
      "----------------------------------------\n",
      "📊 Bulunan dosyalar - Görüntü: 7706, Etiket: 7706\n",
      "📈 Etiketli dosyalar: 3701\n",
      "📉 Boş etiketli dosyalar (dahil edilen): 385\n",
      "📊 Toplam işlenecek dosya: 4086\n",
      "📊 Toplam Eğitim/Doğrulama Sayısı: 3269 / 817\n",
      "📥 Eğitim verileri kopyalanıyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Copy: 100%|██████████| 3269/3269 [00:41<00:00, 78.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Doğrulama verileri kopyalanıyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val Copy: 100%|██████████| 817/817 [00:10<00:00, 77.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ train için dataset split tamamlandı!\n",
      "✅ India başarıyla tamamlandı!\n",
      "\n",
      "🚀 İşleniyor: China_MotorBike\n",
      "----------------------------------------\n",
      "📊 Bulunan dosyalar - Görüntü: 1977, Etiket: 1977\n",
      "📈 Etiketli dosyalar: 1977\n",
      "📉 Boş etiketli dosyalar (dahil edilen): 0\n",
      "📊 Toplam işlenecek dosya: 1977\n",
      "📊 Toplam Eğitim/Doğrulama Sayısı: 1582 / 395\n",
      "📥 Eğitim verileri kopyalanıyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Copy: 100%|██████████| 1582/1582 [00:22<00:00, 70.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Doğrulama verileri kopyalanıyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val Copy: 100%|██████████| 395/395 [00:05<00:00, 76.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ train için dataset split tamamlandı!\n",
      "✅ China_MotorBike başarıyla tamamlandı!\n",
      "\n",
      "🚀 İşleniyor: China_Drone\n",
      "----------------------------------------\n",
      "📊 Bulunan dosyalar - Görüntü: 2401, Etiket: 2401\n",
      "📈 Etiketli dosyalar: 2396\n",
      "📉 Boş etiketli dosyalar (dahil edilen): 5\n",
      "📊 Toplam işlenecek dosya: 2401\n",
      "📊 Toplam Eğitim/Doğrulama Sayısı: 1921 / 480\n",
      "📥 Eğitim verileri kopyalanıyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Copy: 100%|██████████| 1921/1921 [00:24<00:00, 78.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Doğrulama verileri kopyalanıyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val Copy: 100%|██████████| 480/480 [00:06<00:00, 71.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ train için dataset split tamamlandı!\n",
      "✅ China_Drone başarıyla tamamlandı!\n",
      "\n",
      "🚀 İşleniyor: Czech\n",
      "----------------------------------------\n",
      "📊 Bulunan dosyalar - Görüntü: 2829, Etiket: 2829\n",
      "📈 Etiketli dosyalar: 1072\n",
      "📉 Boş etiketli dosyalar (dahil edilen): 141\n",
      "📊 Toplam işlenecek dosya: 1213\n",
      "📊 Toplam Eğitim/Doğrulama Sayısı: 970 / 243\n",
      "📥 Eğitim verileri kopyalanıyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Copy: 100%|██████████| 970/970 [00:13<00:00, 69.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Doğrulama verileri kopyalanıyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val Copy: 100%|██████████| 243/243 [00:03<00:00, 65.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ train için dataset split tamamlandı!\n",
      "✅ Czech başarıyla tamamlandı!\n",
      "\n",
      "🚀 İşleniyor: Norway\n",
      "----------------------------------------\n",
      "📊 Bulunan dosyalar - Görüntü: 8161, Etiket: 8161\n",
      "📈 Etiketli dosyalar: 2914\n",
      "📉 Boş etiketli dosyalar (dahil edilen): 408\n",
      "📊 Toplam işlenecek dosya: 3322\n",
      "📊 Toplam Eğitim/Doğrulama Sayısı: 2658 / 664\n",
      "📥 Eğitim verileri kopyalanıyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Copy: 100%|██████████| 2658/2658 [00:42<00:00, 62.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Doğrulama verileri kopyalanıyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val Copy: 100%|██████████| 664/664 [00:10<00:00, 60.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ train için dataset split tamamlandı!\n",
      "✅ Norway başarıyla tamamlandı!\n",
      "\n",
      "🚀 İşleniyor: United_States\n",
      "----------------------------------------\n",
      "📊 Bulunan dosyalar - Görüntü: 4805, Etiket: 4805\n",
      "📈 Etiketli dosyalar: 4805\n",
      "📉 Boş etiketli dosyalar (dahil edilen): 0\n",
      "📊 Toplam işlenecek dosya: 4805\n",
      "📊 Toplam Eğitim/Doğrulama Sayısı: 3844 / 961\n",
      "📥 Eğitim verileri kopyalanıyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Copy: 100%|██████████| 3844/3844 [00:52<00:00, 72.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Doğrulama verileri kopyalanıyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val Copy: 100%|██████████| 961/961 [00:12<00:00, 74.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ train için dataset split tamamlandı!\n",
      "✅ United_States başarıyla tamamlandı!\n",
      "\n",
      "============================================================\n",
      "📋 İŞLEM ÖZETİ\n",
      "============================================================\n",
      "\n",
      "✅ BAŞARILI ÜLKELER (7):\n",
      "   - Japan\n",
      "   - India\n",
      "   - China_MotorBike\n",
      "   - China_Drone\n",
      "   - Czech\n",
      "   - Norway\n",
      "   - United_States\n",
      "\n",
      "🎉 Dataset split işlemi tamamlandı!\n",
      "📁 Çıktı dizini: C:\\Users\\fthgz\\OneDrive\\Belgeler\\RoadDamageDetection-main\\RDD2022_SPLIT\n",
      "\n",
      "📊 Final dataset yapısı:\n",
      "RDD2022_SPLIT/\n",
      "├── images/\n",
      "│   ├── train/\n",
      "│   └── val/\n",
      "└── labels/\n",
      "    ├── train/\n",
      "    └── val/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Ana dizin\n",
    "ROOTDIR = r\"C:\\Users\\fthgz\\OneDrive\\Belgeler\\RoadDamageDetection-main\"\n",
    "\n",
    "# İşlenecek ülkeler\n",
    "COUNTRIES = [\"Japan\", \"India\", \"China_MotorBike\", \"China_Drone\", \"Czech\", \"Norway\", \"United_States\"]\n",
    "\n",
    "print(\"🌍 Tüm ülkeler için dataset split işlemi başlatılıyor...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "successful_countries = []\n",
    "failed_countries = []\n",
    "\n",
    "for country in COUNTRIES:\n",
    "    # Dizin yapısı: RDD2022_all_countries/{country}/{country}/train\n",
    "    base_train_dir = os.path.join(ROOTDIR, \"RDD2022_all_countries\", country, country, \"train\")\n",
    "    \n",
    "    if os.path.exists(base_train_dir):\n",
    "        print(f\"\\n🚀 İşleniyor: {country}\")\n",
    "        print(\"-\" * 40)\n",
    "        try:\n",
    "            CopyDatasetSplit(base_train_dir)\n",
    "            successful_countries.append(country)\n",
    "            print(f\"✅ {country} başarıyla tamamlandı!\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ {country} işlenirken hata: {e}\")\n",
    "            failed_countries.append(country)\n",
    "    else:\n",
    "        print(f\"⚠️ Dizin bulunamadı: {base_train_dir}\")\n",
    "        failed_countries.append(country)\n",
    "\n",
    "# Özet rapor\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"📋 İŞLEM ÖZETİ\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\n✅ BAŞARILI ÜLKELER ({len(successful_countries)}):\")\n",
    "for country in successful_countries:\n",
    "    print(f\"   - {country}\")\n",
    "\n",
    "if failed_countries:\n",
    "    print(f\"\\n❌ BAŞARISIZ ÜLKELER ({len(failed_countries)}):\")\n",
    "    for country in failed_countries:\n",
    "        print(f\"   - {country}\")\n",
    "\n",
    "print(f\"\\n🎉 Dataset split işlemi tamamlandı!\")\n",
    "print(f\"📁 Çıktı dizini: {ROOTDIR}\\\\RDD2022_SPLIT\")\n",
    "print(\"\\n📊 Final dataset yapısı:\")\n",
    "print(\"RDD2022_SPLIT/\")\n",
    "print(\"├── images/\")\n",
    "print(\"│   ├── train/\")\n",
    "print(\"│   └── val/\")\n",
    "print(\"└── labels/\")\n",
    "print(\"    ├── train/\")\n",
    "print(\"    └── val/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Too many parameters - -d\n"
     ]
    }
   ],
   "source": [
    "!tree ./ -d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
