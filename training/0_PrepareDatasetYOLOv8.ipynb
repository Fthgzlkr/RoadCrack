{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Immport\n",
    "from xml.dom import minidom\n",
    "import bs4 as bs\n",
    "import os\n",
    "from pathlib import Path\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import os\n",
    "from pathlib import Path\n",
    "import bs4 as bs\n",
    "\n",
    "def convertPascal2YOLOv8(filePath, outputDir):\n",
    "    \"\"\"\n",
    "    Pascal VOC formatÄ±ndaki XML dosyalarÄ±nÄ± YOLOv8 formatÄ±na Ã§evirir\n",
    "    ID'leri ardÄ±ÅŸÄ±k olacak ÅŸekilde yeniden dÃ¼zenler (0-7)\n",
    "    \"\"\"\n",
    "    # âš ï¸ YENÄ° ARDIIÅIK ID MAPPING (0-7, boÅŸluk yok)\n",
    "    class_mapping = {\n",
    "        \"D00\": 0,     # Longitudinal Crack\n",
    "        \"D10\": 1,     # Transverse Crack\n",
    "        \"D20\": 2,     # Alligator Crack\n",
    "        \"D40\": 3,     # Pothole\n",
    "        \"D43\": 4,     # Crosswalk Blur (ESKÄ°: 6 â†’ YENÄ°: 4)\n",
    "        \"D44\": 5,     # White Line (ESKÄ°: 7 â†’ YENÄ°: 5)\n",
    "        \"D50\": 6,     # Utility Hole (ESKÄ°: 8 â†’ YENÄ°: 6)\n",
    "        \"Repair\": 7   # Repair (ESKÄ°: 9 â†’ YENÄ°: 7)\n",
    "    }\n",
    "\n",
    "    # Sadece bunlar yazÄ±lacak\n",
    "    included_classes = {\"D00\", \"D10\", \"D20\", \"D40\", \"D43\", \"D44\", \"D50\", \"Repair\"}\n",
    "\n",
    "    written_class_counter = Counter()\n",
    "    ignored_class_counter = Counter()\n",
    "\n",
    "    try:\n",
    "        with open(filePath, \"r\", encoding=\"utf-8\") as file:\n",
    "            contents = file.read()\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Dosya okuma hatasÄ±: {filePath} - {e}\")\n",
    "        return written_class_counter, ignored_class_counter\n",
    "\n",
    "    soup = bs.BeautifulSoup(contents, 'lxml-xml')\n",
    "    \n",
    "    # GÃ¶rÃ¼ntÃ¼ boyutlarÄ±nÄ± al\n",
    "    size_tag = soup.find(\"size\")\n",
    "    if not size_tag:\n",
    "        print(f\"âš ï¸ UyarÄ±: {filePath} dosyasÄ±nda size tag bulunamadÄ±!\")\n",
    "        return written_class_counter, ignored_class_counter\n",
    "        \n",
    "    try:\n",
    "        image_width = int(size_tag.find(\"width\").text)\n",
    "        image_height = int(size_tag.find(\"height\").text)\n",
    "    except (ValueError, AttributeError) as e:\n",
    "        print(f\"âš ï¸ GÃ¶rÃ¼ntÃ¼ boyut hatasÄ±: {filePath} - {e}\")\n",
    "        return written_class_counter, ignored_class_counter\n",
    "\n",
    "    objects = soup.find_all(\"object\")\n",
    "    output_lines = []\n",
    "\n",
    "    for obj in objects:\n",
    "        try:\n",
    "            class_name = obj.find(\"name\").text.strip()\n",
    "        except AttributeError:\n",
    "            continue\n",
    "\n",
    "        # SÄ±nÄ±f dahil edilmeyecekse atla\n",
    "        if class_name not in included_classes:\n",
    "            ignored_class_counter[class_name] += 1\n",
    "            continue\n",
    "\n",
    "        # Mapping'de yoksa atla  \n",
    "        if class_name not in class_mapping:\n",
    "            ignored_class_counter[class_name] += 1\n",
    "            continue\n",
    "\n",
    "        # YENÄ° ardÄ±ÅŸÄ±k ID'yi al\n",
    "        class_id = class_mapping[class_name]\n",
    "\n",
    "        # Bounding box koordinatlarÄ±nÄ± al\n",
    "        try:\n",
    "            bbox = obj.find(\"bndbox\")\n",
    "            xmin = float(bbox.find(\"xmin\").text)\n",
    "            ymin = float(bbox.find(\"ymin\").text)\n",
    "            xmax = float(bbox.find(\"xmax\").text)\n",
    "            ymax = float(bbox.find(\"ymax\").text)\n",
    "        except (ValueError, AttributeError) as e:\n",
    "            print(f\"âš ï¸ Bbox hatasÄ± {class_name}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # YOLO formatÄ±na Ã§evir\n",
    "        w = xmax - xmin\n",
    "        h = ymax - ymin\n",
    "        cx = xmin + w / 2\n",
    "        cy = ymin + h / 2\n",
    "\n",
    "        # Normalize et\n",
    "        w /= image_width\n",
    "        h /= image_height\n",
    "        cx /= image_width\n",
    "        cy /= image_height\n",
    "\n",
    "        # GeÃ§erli koordinat kontrolÃ¼\n",
    "        if w <= 0 or h <= 0 or cx < 0 or cy < 0 or cx > 1 or cy > 1:\n",
    "            print(f\"âš ï¸ GeÃ§ersiz koordinat {class_name}: cx={cx:.3f}, cy={cy:.3f}, w={w:.3f}, h={h:.3f}\")\n",
    "            continue\n",
    "\n",
    "        # YENÄ° ID ile YOLO formatÄ±nda yaz\n",
    "        output_lines.append(f\"{class_id} {cx:.6f} {cy:.6f} {w:.6f} {h:.6f}\\n\")\n",
    "        written_class_counter[class_name] += 1\n",
    "\n",
    "    # Ã‡Ä±ktÄ± dosyasÄ± oluÅŸtur (boÅŸ olsa bile)\n",
    "    outputFilename = os.path.splitext(os.path.basename(filePath))[0] + \".txt\"\n",
    "    os.makedirs(outputDir, exist_ok=True)\n",
    "    outputPath = Path(outputDir) / outputFilename\n",
    "\n",
    "    with open(outputPath, 'w') as f:\n",
    "        f.writelines(output_lines)\n",
    "\n",
    "    return written_class_counter, ignored_class_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ XML dosyalarÄ±nÄ± YOLO formatÄ±na Ã§evirme iÅŸlemi baÅŸlatÄ±lÄ±yor...\n",
      "======================================================================\n",
      "\n",
      "ğŸ” xmls klasÃ¶rÃ¼nde 10506 XML bulundu.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing xmls:  10%|â–‰         | 1014/10506 [00:12<01:54, 82.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ GeÃ§ersiz koordinat D20: cx=0.330, cy=0.791, w=0.000, h=0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing xmls: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10506/10506 [02:14<00:00, 78.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” xmls klasÃ¶rÃ¼nde 7706 XML bulundu.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing xmls: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7706/7706 [01:21<00:00, 94.50it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” xmls klasÃ¶rÃ¼nde 2401 XML bulundu.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing xmls: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2401/2401 [00:28<00:00, 84.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” xmls klasÃ¶rÃ¼nde 1977 XML bulundu.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing xmls: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1977/1977 [00:27<00:00, 72.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” xmls klasÃ¶rÃ¼nde 2829 XML bulundu.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing xmls: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2829/2829 [00:31<00:00, 89.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” xmls klasÃ¶rÃ¼nde 8161 XML bulundu.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing xmls: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8161/8161 [01:40<00:00, 80.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” xmls klasÃ¶rÃ¼nde 4805 XML bulundu.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing xmls: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4805/4805 [00:58<00:00, 81.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸ“Š TÃœM DOSYALAR Ä°Ã‡Ä°N TOPLAM SINIF Ä°STATÄ°STÄ°KLERÄ°\n",
      "======================================================================\n",
      "\n",
      "âœ… YAZILAN SINIFLAR TOPLAM SAYISI:\n",
      " - D00: 26,016 adet\n",
      " - D10: 11,830 adet\n",
      " - D20: 10,616 adet\n",
      " - D40: 6,544 adet\n",
      " - D43: 793 adet\n",
      " - D44: 5,057 adet\n",
      " - D50: 3,581 adet\n",
      " - Repair: 1,046 adet\n",
      "\n",
      "ğŸ“ˆ Toplam yazÄ±lan nesne sayÄ±sÄ±: 65,483\n",
      "\n",
      "âŒ YAZILMAYAN SINIFLAR TOPLAM SAYISI:\n",
      "Toplam atlanan nesne sayÄ±sÄ±: 228\n",
      " - Block crack: 3 adet\n",
      " - D01: 179 adet\n",
      " - D0w0: 1 adet\n",
      " - D11: 45 adet\n",
      "\n",
      "ğŸ‰ XML â†’ YOLO dÃ¶nÃ¼ÅŸÃ¼mÃ¼ tamamlandÄ±!\n",
      "ğŸ“ Label dosyalarÄ± her Ã¼lkenin 'labels' klasÃ¶rÃ¼nde oluÅŸturuldu.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "# Ana dizin\n",
    "ROOTDIR = r\"C:\\Users\\fthgz\\OneDrive\\Belgeler\\RoadDamageDetection-main\"\n",
    "\n",
    "# Ä°ÅŸlenecek Ã¼lkeler\n",
    "CountryListDir = [\n",
    "    \"RDD2022_all_countries/Japan/Japan/train/annotations/xmls\",\n",
    "    \"RDD2022_all_countries/India/India/train/annotations/xmls\",\n",
    "    \"RDD2022_all_countries/China_Drone/China_Drone/train/annotations/xmls\",\n",
    "    \"RDD2022_all_countries/China_MotorBike/China_MotorBike/train/annotations/xmls\",\n",
    "    \"RDD2022_all_countries/Czech/Czech/train/annotations/xmls\",\n",
    "    \"RDD2022_all_countries/Norway/Norway/train/annotations/xmls\",\n",
    "    \"RDD2022_all_countries/United_States/United_States/train/annotations/xmls\",\n",
    "]\n",
    "\n",
    "# Toplam sayaÃ§lar\n",
    "total_written_counter = Counter()\n",
    "total_ignored_counter = Counter()\n",
    "\n",
    "print(\"ğŸš€ XML dosyalarÄ±nÄ± YOLO formatÄ±na Ã§evirme iÅŸlemi baÅŸlatÄ±lÄ±yor...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for country_rel_path in CountryListDir:\n",
    "    country_abs_path = os.path.join(ROOTDIR, country_rel_path)\n",
    "    \n",
    "    # Dizin kontrolÃ¼\n",
    "    if not os.path.exists(country_abs_path):\n",
    "        print(f\"âš ï¸ Dizin bulunamadÄ±: {country_abs_path}\")\n",
    "        continue\n",
    "    \n",
    "    # XML dosyalarÄ±nÄ± bul\n",
    "    fileList = sorted(glob.glob(os.path.join(country_abs_path, \"*.xml\")))\n",
    "    \n",
    "    if not fileList:\n",
    "        print(f\"âš ï¸ {country_rel_path} klasÃ¶rÃ¼nde XML dosyasÄ± bulunamadÄ±.\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\nğŸ” {os.path.basename(country_rel_path)} klasÃ¶rÃ¼nde {len(fileList)} XML bulundu.\")\n",
    "    \n",
    "    # Ã‡Ä±ktÄ± dizinini belirle (labels klasÃ¶rÃ¼ oluÅŸtur)\n",
    "    output_labels_path = Path(country_abs_path).parent.parent / \"labels\"\n",
    "    \n",
    "    # Her XML dosyasÄ±nÄ± iÅŸle\n",
    "    for file in tqdm(fileList, desc=f\"Processing {os.path.basename(country_rel_path)}\"):\n",
    "        written, ignored = convertPascal2YOLOv8(file, output_labels_path)\n",
    "        total_written_counter.update(written)\n",
    "        total_ignored_counter.update(ignored)\n",
    "\n",
    "# Ä°ÅŸlem bitince toplu istatistikleri yazdÄ±r\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ“Š TÃœM DOSYALAR Ä°Ã‡Ä°N TOPLAM SINIF Ä°STATÄ°STÄ°KLERÄ°\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nâœ… YAZILAN SINIFLAR TOPLAM SAYISI:\")\n",
    "if total_written_counter:\n",
    "    for cls, count in sorted(total_written_counter.items()):\n",
    "        print(f\" - {cls}: {count:,} adet\")\n",
    "    print(f\"\\nğŸ“ˆ Toplam yazÄ±lan nesne sayÄ±sÄ±: {sum(total_written_counter.values()):,}\")\n",
    "else:\n",
    "    print(\" HiÃ§ nesne yazÄ±lmadÄ±!\")\n",
    "\n",
    "print(\"\\nâŒ YAZILMAYAN SINIFLAR TOPLAM SAYISI:\")\n",
    "if total_ignored_counter:\n",
    "    total_ignored = sum(total_ignored_counter.values())\n",
    "    print(f\"Toplam atlanan nesne sayÄ±sÄ±: {total_ignored:,}\")\n",
    "    for cls, count in sorted(total_ignored_counter.items()):\n",
    "        print(f\" - {cls}: {count:,} adet\")\n",
    "else:\n",
    "    print(\" HiÃ§ nesne atlanmadÄ±!\")\n",
    "\n",
    "print(f\"\\nğŸ‰ XML â†’ YOLO dÃ¶nÃ¼ÅŸÃ¼mÃ¼ tamamlandÄ±!\")\n",
    "print(f\"ğŸ“ Label dosyalarÄ± her Ã¼lkenin 'labels' klasÃ¶rÃ¼nde oluÅŸturuldu.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "def CopyDatasetSplit(baseDir):\n",
    "    \"\"\"\n",
    "    Veri setini %80 eÄŸitim, %20 doÄŸrulama olarak bÃ¶ler ve kopyalar\n",
    "    BoÅŸ etiketli gÃ¶rÃ¼ntÃ¼leri %5 oranÄ±nda dahil eder\n",
    "    \"\"\"\n",
    "    random.seed(1337)  # Reproducible results\n",
    "    \n",
    "    baseOutputDir = r\"C:\\Users\\fthgz\\OneDrive\\Belgeler\\RoadDamageDetection-main\\RDD2022_SPLIT\"\n",
    "    \n",
    "    baseImageDir = os.path.join(baseDir, \"images\")\n",
    "    baseAnnotDir = os.path.join(baseDir, \"labels\")\n",
    "    \n",
    "    # Dizin kontrolÃ¼\n",
    "    if not os.path.exists(baseImageDir):\n",
    "        print(f\"âš ï¸ Images dizini bulunamadÄ±: {baseImageDir}\")\n",
    "        return\n",
    "        \n",
    "    if not os.path.exists(baseAnnotDir):\n",
    "        print(f\"âš ï¸ Labels dizini bulunamadÄ±: {baseAnnotDir}\")\n",
    "        return\n",
    "    \n",
    "    # TÃ¼m dosyalarÄ± listele\n",
    "    image_list_all = sorted(glob.glob(os.path.join(baseImageDir, \"*\")))\n",
    "    annot_list_all = sorted(glob.glob(os.path.join(baseAnnotDir, \"*\")))\n",
    "    \n",
    "    if not image_list_all:\n",
    "        print(f\"âš ï¸ HiÃ§ gÃ¶rÃ¼ntÃ¼ dosyasÄ± bulunamadÄ±: {baseImageDir}\")\n",
    "        return\n",
    "        \n",
    "    if not annot_list_all:\n",
    "        print(f\"âš ï¸ HiÃ§ etiket dosyasÄ± bulunamadÄ±: {baseAnnotDir}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"ğŸ“Š Bulunan dosyalar - GÃ¶rÃ¼ntÃ¼: {len(image_list_all)}, Etiket: {len(annot_list_all)}\")\n",
    "    \n",
    "    # ğŸŸ¡ BoÅŸ etiketli gÃ¶rÃ¼ntÃ¼ler %5 oranÄ±nda dahil edilecek\n",
    "    backgroundImages_Percentage = 0.05\n",
    "    image_list = []\n",
    "    annot_list = []\n",
    "    max_background_image = int(len(image_list_all) * backgroundImages_Percentage)\n",
    "    background_counter = 0\n",
    "    files_with_labels = 0\n",
    "    \n",
    "    # Dosya eÅŸleÅŸtirmesi ve filtreleme\n",
    "    min_length = min(len(image_list_all), len(annot_list_all))\n",
    "    \n",
    "    for i in range(min_length):\n",
    "        try:\n",
    "            with open(annot_list_all[i], 'r', encoding='utf-8') as f:\n",
    "                annot_content = f.read().strip()\n",
    "                \n",
    "            if annot_content:  # Etiket varsa\n",
    "                image_list.append(image_list_all[i])\n",
    "                annot_list.append(annot_list_all[i])\n",
    "                files_with_labels += 1\n",
    "            elif background_counter < max_background_image:  # BoÅŸ etiket ama limitte\n",
    "                image_list.append(image_list_all[i])\n",
    "                annot_list.append(annot_list_all[i])\n",
    "                background_counter += 1\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Dosya okuma hatasÄ±: {annot_list_all[i]} - {e}\")\n",
    "            continue\n",
    "    \n",
    "    if not image_list:\n",
    "        print(\"âš ï¸ Ä°ÅŸlenecek dosya bulunamadÄ±!\")\n",
    "        return\n",
    "    \n",
    "    print(f\"ğŸ“ˆ Etiketli dosyalar: {files_with_labels}\")\n",
    "    print(f\"ğŸ“‰ BoÅŸ etiketli dosyalar (dahil edilen): {background_counter}\")\n",
    "    print(f\"ğŸ“Š Toplam iÅŸlenecek dosya: {len(image_list)}\")\n",
    "    \n",
    "    # ğŸ”€ %80 eÄŸitim, %20 doÄŸrulama\n",
    "    dataset_length = len(image_list)\n",
    "    split_ratio = 0.8\n",
    "    middle_point = round(split_ratio * dataset_length)\n",
    "    \n",
    "    numberList = list(range(dataset_length))\n",
    "    random.shuffle(numberList)\n",
    "    trainNumberList = numberList[:middle_point]\n",
    "    validNumberList = numberList[middle_point:]\n",
    "    \n",
    "    print(f\"ğŸ“Š Toplam EÄŸitim/DoÄŸrulama SayÄ±sÄ±: {len(trainNumberList)} / {len(validNumberList)}\")\n",
    "    \n",
    "    # ğŸŸ© EÄŸitim verileri\n",
    "    print(\"ğŸ“¥ EÄŸitim verileri kopyalanÄ±yor...\")\n",
    "    train_images_dir = os.path.join(baseOutputDir, \"images\", \"train\")\n",
    "    train_labels_dir = os.path.join(baseOutputDir, \"labels\", \"train\")\n",
    "    os.makedirs(train_images_dir, exist_ok=True)\n",
    "    os.makedirs(train_labels_dir, exist_ok=True)\n",
    "    \n",
    "    for i in tqdm(trainNumberList, desc=\"Train Copy\"):\n",
    "        try:\n",
    "            shutil.copy2(image_list[i], train_images_dir)\n",
    "            shutil.copy2(annot_list[i], train_labels_dir)\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ EÄŸitim kopyalama hatasÄ±: {e}\")\n",
    "    \n",
    "    # ğŸŸ¦ DoÄŸrulama verileri\n",
    "    print(\"ğŸ“¥ DoÄŸrulama verileri kopyalanÄ±yor...\")\n",
    "    val_images_dir = os.path.join(baseOutputDir, \"images\", \"val\")\n",
    "    val_labels_dir = os.path.join(baseOutputDir, \"labels\", \"val\")\n",
    "    os.makedirs(val_images_dir, exist_ok=True)\n",
    "    os.makedirs(val_labels_dir, exist_ok=True)\n",
    "    \n",
    "    for i in tqdm(validNumberList, desc=\"Val Copy\"):\n",
    "        try:\n",
    "            shutil.copy2(image_list[i], val_images_dir)\n",
    "            shutil.copy2(annot_list[i], val_labels_dir)\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ DoÄŸrulama kopyalama hatasÄ±: {e}\")\n",
    "    \n",
    "    print(f\"âœ… {os.path.basename(baseDir)} iÃ§in dataset split tamamlandÄ±!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸŒ TÃ¼m Ã¼lkeler iÃ§in dataset split iÅŸlemi baÅŸlatÄ±lÄ±yor...\n",
      "============================================================\n",
      "\n",
      "ğŸš€ Ä°ÅŸleniyor: Japan\n",
      "----------------------------------------\n",
      "ğŸ“Š Bulunan dosyalar - GÃ¶rÃ¼ntÃ¼: 10506, Etiket: 10506\n",
      "ğŸ“ˆ Etiketli dosyalar: 9712\n",
      "ğŸ“‰ BoÅŸ etiketli dosyalar (dahil edilen): 525\n",
      "ğŸ“Š Toplam iÅŸlenecek dosya: 10237\n",
      "ğŸ“Š Toplam EÄŸitim/DoÄŸrulama SayÄ±sÄ±: 8190 / 2047\n",
      "ğŸ“¥ EÄŸitim verileri kopyalanÄ±yor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Copy: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8190/8190 [01:44<00:00, 78.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¥ DoÄŸrulama verileri kopyalanÄ±yor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val Copy: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2047/2047 [00:26<00:00, 76.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… train iÃ§in dataset split tamamlandÄ±!\n",
      "âœ… Japan baÅŸarÄ±yla tamamlandÄ±!\n",
      "\n",
      "ğŸš€ Ä°ÅŸleniyor: India\n",
      "----------------------------------------\n",
      "ğŸ“Š Bulunan dosyalar - GÃ¶rÃ¼ntÃ¼: 7706, Etiket: 7706\n",
      "ğŸ“ˆ Etiketli dosyalar: 3701\n",
      "ğŸ“‰ BoÅŸ etiketli dosyalar (dahil edilen): 385\n",
      "ğŸ“Š Toplam iÅŸlenecek dosya: 4086\n",
      "ğŸ“Š Toplam EÄŸitim/DoÄŸrulama SayÄ±sÄ±: 3269 / 817\n",
      "ğŸ“¥ EÄŸitim verileri kopyalanÄ±yor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Copy: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3269/3269 [00:41<00:00, 78.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¥ DoÄŸrulama verileri kopyalanÄ±yor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val Copy: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 817/817 [00:10<00:00, 77.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… train iÃ§in dataset split tamamlandÄ±!\n",
      "âœ… India baÅŸarÄ±yla tamamlandÄ±!\n",
      "\n",
      "ğŸš€ Ä°ÅŸleniyor: China_MotorBike\n",
      "----------------------------------------\n",
      "ğŸ“Š Bulunan dosyalar - GÃ¶rÃ¼ntÃ¼: 1977, Etiket: 1977\n",
      "ğŸ“ˆ Etiketli dosyalar: 1977\n",
      "ğŸ“‰ BoÅŸ etiketli dosyalar (dahil edilen): 0\n",
      "ğŸ“Š Toplam iÅŸlenecek dosya: 1977\n",
      "ğŸ“Š Toplam EÄŸitim/DoÄŸrulama SayÄ±sÄ±: 1582 / 395\n",
      "ğŸ“¥ EÄŸitim verileri kopyalanÄ±yor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Copy: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1582/1582 [00:22<00:00, 70.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¥ DoÄŸrulama verileri kopyalanÄ±yor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val Copy: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 395/395 [00:05<00:00, 76.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… train iÃ§in dataset split tamamlandÄ±!\n",
      "âœ… China_MotorBike baÅŸarÄ±yla tamamlandÄ±!\n",
      "\n",
      "ğŸš€ Ä°ÅŸleniyor: China_Drone\n",
      "----------------------------------------\n",
      "ğŸ“Š Bulunan dosyalar - GÃ¶rÃ¼ntÃ¼: 2401, Etiket: 2401\n",
      "ğŸ“ˆ Etiketli dosyalar: 2396\n",
      "ğŸ“‰ BoÅŸ etiketli dosyalar (dahil edilen): 5\n",
      "ğŸ“Š Toplam iÅŸlenecek dosya: 2401\n",
      "ğŸ“Š Toplam EÄŸitim/DoÄŸrulama SayÄ±sÄ±: 1921 / 480\n",
      "ğŸ“¥ EÄŸitim verileri kopyalanÄ±yor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Copy: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1921/1921 [00:24<00:00, 78.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¥ DoÄŸrulama verileri kopyalanÄ±yor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val Copy: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 480/480 [00:06<00:00, 71.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… train iÃ§in dataset split tamamlandÄ±!\n",
      "âœ… China_Drone baÅŸarÄ±yla tamamlandÄ±!\n",
      "\n",
      "ğŸš€ Ä°ÅŸleniyor: Czech\n",
      "----------------------------------------\n",
      "ğŸ“Š Bulunan dosyalar - GÃ¶rÃ¼ntÃ¼: 2829, Etiket: 2829\n",
      "ğŸ“ˆ Etiketli dosyalar: 1072\n",
      "ğŸ“‰ BoÅŸ etiketli dosyalar (dahil edilen): 141\n",
      "ğŸ“Š Toplam iÅŸlenecek dosya: 1213\n",
      "ğŸ“Š Toplam EÄŸitim/DoÄŸrulama SayÄ±sÄ±: 970 / 243\n",
      "ğŸ“¥ EÄŸitim verileri kopyalanÄ±yor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Copy: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 970/970 [00:13<00:00, 69.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¥ DoÄŸrulama verileri kopyalanÄ±yor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val Copy: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [00:03<00:00, 65.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… train iÃ§in dataset split tamamlandÄ±!\n",
      "âœ… Czech baÅŸarÄ±yla tamamlandÄ±!\n",
      "\n",
      "ğŸš€ Ä°ÅŸleniyor: Norway\n",
      "----------------------------------------\n",
      "ğŸ“Š Bulunan dosyalar - GÃ¶rÃ¼ntÃ¼: 8161, Etiket: 8161\n",
      "ğŸ“ˆ Etiketli dosyalar: 2914\n",
      "ğŸ“‰ BoÅŸ etiketli dosyalar (dahil edilen): 408\n",
      "ğŸ“Š Toplam iÅŸlenecek dosya: 3322\n",
      "ğŸ“Š Toplam EÄŸitim/DoÄŸrulama SayÄ±sÄ±: 2658 / 664\n",
      "ğŸ“¥ EÄŸitim verileri kopyalanÄ±yor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Copy: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2658/2658 [00:42<00:00, 62.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¥ DoÄŸrulama verileri kopyalanÄ±yor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val Copy: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 664/664 [00:10<00:00, 60.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… train iÃ§in dataset split tamamlandÄ±!\n",
      "âœ… Norway baÅŸarÄ±yla tamamlandÄ±!\n",
      "\n",
      "ğŸš€ Ä°ÅŸleniyor: United_States\n",
      "----------------------------------------\n",
      "ğŸ“Š Bulunan dosyalar - GÃ¶rÃ¼ntÃ¼: 4805, Etiket: 4805\n",
      "ğŸ“ˆ Etiketli dosyalar: 4805\n",
      "ğŸ“‰ BoÅŸ etiketli dosyalar (dahil edilen): 0\n",
      "ğŸ“Š Toplam iÅŸlenecek dosya: 4805\n",
      "ğŸ“Š Toplam EÄŸitim/DoÄŸrulama SayÄ±sÄ±: 3844 / 961\n",
      "ğŸ“¥ EÄŸitim verileri kopyalanÄ±yor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Copy: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3844/3844 [00:52<00:00, 72.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¥ DoÄŸrulama verileri kopyalanÄ±yor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val Copy: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 961/961 [00:12<00:00, 74.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… train iÃ§in dataset split tamamlandÄ±!\n",
      "âœ… United_States baÅŸarÄ±yla tamamlandÄ±!\n",
      "\n",
      "============================================================\n",
      "ğŸ“‹ Ä°ÅLEM Ã–ZETÄ°\n",
      "============================================================\n",
      "\n",
      "âœ… BAÅARILI ÃœLKELER (7):\n",
      "   - Japan\n",
      "   - India\n",
      "   - China_MotorBike\n",
      "   - China_Drone\n",
      "   - Czech\n",
      "   - Norway\n",
      "   - United_States\n",
      "\n",
      "ğŸ‰ Dataset split iÅŸlemi tamamlandÄ±!\n",
      "ğŸ“ Ã‡Ä±ktÄ± dizini: C:\\Users\\fthgz\\OneDrive\\Belgeler\\RoadDamageDetection-main\\RDD2022_SPLIT\n",
      "\n",
      "ğŸ“Š Final dataset yapÄ±sÄ±:\n",
      "RDD2022_SPLIT/\n",
      "â”œâ”€â”€ images/\n",
      "â”‚   â”œâ”€â”€ train/\n",
      "â”‚   â””â”€â”€ val/\n",
      "â””â”€â”€ labels/\n",
      "    â”œâ”€â”€ train/\n",
      "    â””â”€â”€ val/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Ana dizin\n",
    "ROOTDIR = r\"C:\\Users\\fthgz\\OneDrive\\Belgeler\\RoadDamageDetection-main\"\n",
    "\n",
    "# Ä°ÅŸlenecek Ã¼lkeler\n",
    "COUNTRIES = [\"Japan\", \"India\", \"China_MotorBike\", \"China_Drone\", \"Czech\", \"Norway\", \"United_States\"]\n",
    "\n",
    "print(\"ğŸŒ TÃ¼m Ã¼lkeler iÃ§in dataset split iÅŸlemi baÅŸlatÄ±lÄ±yor...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "successful_countries = []\n",
    "failed_countries = []\n",
    "\n",
    "for country in COUNTRIES:\n",
    "    # Dizin yapÄ±sÄ±: RDD2022_all_countries/{country}/{country}/train\n",
    "    base_train_dir = os.path.join(ROOTDIR, \"RDD2022_all_countries\", country, country, \"train\")\n",
    "    \n",
    "    if os.path.exists(base_train_dir):\n",
    "        print(f\"\\nğŸš€ Ä°ÅŸleniyor: {country}\")\n",
    "        print(\"-\" * 40)\n",
    "        try:\n",
    "            CopyDatasetSplit(base_train_dir)\n",
    "            successful_countries.append(country)\n",
    "            print(f\"âœ… {country} baÅŸarÄ±yla tamamlandÄ±!\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ {country} iÅŸlenirken hata: {e}\")\n",
    "            failed_countries.append(country)\n",
    "    else:\n",
    "        print(f\"âš ï¸ Dizin bulunamadÄ±: {base_train_dir}\")\n",
    "        failed_countries.append(country)\n",
    "\n",
    "# Ã–zet rapor\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“‹ Ä°ÅLEM Ã–ZETÄ°\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nâœ… BAÅARILI ÃœLKELER ({len(successful_countries)}):\")\n",
    "for country in successful_countries:\n",
    "    print(f\"   - {country}\")\n",
    "\n",
    "if failed_countries:\n",
    "    print(f\"\\nâŒ BAÅARISIZ ÃœLKELER ({len(failed_countries)}):\")\n",
    "    for country in failed_countries:\n",
    "        print(f\"   - {country}\")\n",
    "\n",
    "print(f\"\\nğŸ‰ Dataset split iÅŸlemi tamamlandÄ±!\")\n",
    "print(f\"ğŸ“ Ã‡Ä±ktÄ± dizini: {ROOTDIR}\\\\RDD2022_SPLIT\")\n",
    "print(\"\\nğŸ“Š Final dataset yapÄ±sÄ±:\")\n",
    "print(\"RDD2022_SPLIT/\")\n",
    "print(\"â”œâ”€â”€ images/\")\n",
    "print(\"â”‚   â”œâ”€â”€ train/\")\n",
    "print(\"â”‚   â””â”€â”€ val/\")\n",
    "print(\"â””â”€â”€ labels/\")\n",
    "print(\"    â”œâ”€â”€ train/\")\n",
    "print(\"    â””â”€â”€ val/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Too many parameters - -d\n"
     ]
    }
   ],
   "source": [
    "!tree ./ -d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
